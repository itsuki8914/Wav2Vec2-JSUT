{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric, Audio\n",
    "import os\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from scipy import arange, around, array, linspace\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import resample\n",
    "from torchaudio import transforms\n",
    "\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_ALL_WEIGHTS = True # すべてのパラメータを学習するか最後の全結合層だけ学習するか\n",
    "lr = 1e-4 #学習率\n",
    "num_train_epochs = 50 #学習するエポック数\n",
    "per_device_train_batch_size = 8# GPU1枚あたりのバッチサイズ(32の約数)\n",
    "torch.backends.cudnn.benchmark = True # 再現性がなくなるが高速化\n",
    "tgt = 'hira' # ラベルの種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>hira</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0161d251e9a710136aba6b9ed96572600657c1f79563b37fe36e77d84509789b879f4468eb74a199be08ea1665a62be94e61d61a47ace02acebfe396d5e34523</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_2769521...</td>\n",
       "      <td>自己が物となること、自己がなくなることではない。</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>じこがものとなることじこがなくなることではない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0161d251e9a710136aba6b9ed96572600657c1f79563b37fe36e77d84509789b879f4468eb74a199be08ea1665a62be94e61d61a47ace02acebfe396d5e34523</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_2769521...</td>\n",
       "      <td>暗証番号をど忘れしてお金を引き出せない</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>あんしょうばんごうをどわすれしておきんをひきだせない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147158368920f5b156bab36fd42423c000f7e1ceee6467a8eaac47989ee0cb1c2d231399fd7fc8ec5635</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_3068695...</td>\n",
       "      <td>それは唯心論でもなく神秘主義でもない。</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>それはゆいしんろんでもなくしんぴしゅぎでもない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147158368920f5b156bab36fd42423c000f7e1ceee6467a8eaac47989ee0cb1c2d231399fd7fc8ec5635</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_3068695...</td>\n",
       "      <td>常識は先ず行為的知識である。</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>じょうしきはまずこういてきちしきである</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147158368920f5b156bab36fd42423c000f7e1ceee6467a8eaac47989ee0cb1c2d231399fd7fc8ec5635</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_3068695...</td>\n",
       "      <td>顔には何かあると書いてあるぞ？</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>かおにはなにかあるとかいてあるぞ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "client_id                                                                                               \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  ./data/processed_clips/common_voice_ja_2769521...   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  ./data/processed_clips/common_voice_ja_2769521...   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...  ./data/processed_clips/common_voice_ja_3068695...   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...  ./data/processed_clips/common_voice_ja_3068695...   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...  ./data/processed_clips/common_voice_ja_3068695...   \n",
       "\n",
       "                                                                    sentence  \\\n",
       "client_id                                                                      \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  自己が物となること、自己がなくなることではない。   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...       暗証番号をど忘れしてお金を引き出せない   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...       それは唯心論でもなく神秘主義でもない。   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...            常識は先ず行為的知識である。   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...           顔には何かあると書いてあるぞ？   \n",
       "\n",
       "                                                    up_votes  down_votes  age  \\\n",
       "client_id                                                                       \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...         2           1  NaN   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...         3           0  NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         2           1  NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         2           0  NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         2           0  NaN   \n",
       "\n",
       "                                                   gender accents locale  \\\n",
       "client_id                                                                  \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...    NaN     NaN     ja   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...    NaN     NaN     ja   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...    NaN     NaN     ja   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...    NaN     NaN     ja   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...    NaN     NaN     ja   \n",
       "\n",
       "                                                   segment  \\\n",
       "client_id                                                    \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...     NaN   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...     NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     NaN   \n",
       "\n",
       "                                                                          hira  \n",
       "client_id                                                                       \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...     じこがものとなることじこがなくなることではない  \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  あんしょうばんごうをどわすれしておきんをひきだせない  \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     それはゆいしんろんでもなくしんぴしゅぎでもない  \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         じょうしきはまずこういてきちしきである  \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...            かおにはなにかあるとかいてあるぞ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(f'./train_{tgt}_wav.csv', index_col=0)\n",
    "val = pd.read_csv(f'./val_{tgt}_wav.csv', index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34215"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = val.reset_index()\n",
    "train = train.reset_index()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='', vocab_size=114, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "tokenizer = Wav2Vec2CTCTokenizer(f\"./vocab_{tgt}.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=sr, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: PreTrainedTokenizer(name_or_path='', vocab_size=114, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "def lpf(wave, fs, fe , n):\n",
    "    nyq = fs / 2.0\n",
    "    b, a = signal.butter(1, fe/nyq, btype='low')\n",
    "    for i in range(0, n):\n",
    "        wave = signal.filtfilt(b, a, wave)\n",
    "    return wave\n",
    "\n",
    "def hpf(wave, fs, fe , n):\n",
    "    nyq = fs / 2.0\n",
    "    b, a = signal.butter(1, fe/nyq, btype='high')\n",
    "    for i in range(0, n):\n",
    "        wave = signal.filtfilt(b, a, wave)\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretch = torchaudio.transforms.TimeStretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2v2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train=False, p_wav=0.75, p_shf=0.75):\n",
    "        self.df = df\n",
    "        self.pathes = df['path'].values\n",
    "        self.sentences = df[tgt].values\n",
    "        self.train = train\n",
    "        self.p_wav = p_wav\n",
    "        self.p_shf = p_shf        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate = torchaudio.load(self.pathes[idx], normalize=True)\n",
    "        batch = dict()\n",
    "        x = processor(waveform.reshape(-1), sampling_rate=sr).input_values[0]  \n",
    "        orig_shape = x.shape\n",
    "        \n",
    "        if self.train:\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                x = torch.Tensor(x)\n",
    "                rate = torch.rand(1).numpy()[0]*0.2 + 0.9 \n",
    "                x = x.reshape(1,1,1,-1)\n",
    "                x = F.interpolate(x, (1,int(rate*x.shape[-1])), mode='bilinear', align_corners=False)\n",
    "                x = x.numpy()\n",
    "                x = x.reshape(-1)\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                x = torch.Tensor(x)\n",
    "                rate = torch.rand(1).numpy()[0]*0.2 + 0.9 \n",
    "                transform = transforms.Resample(sample_rate, int(sample_rate*rate))\n",
    "                x = transform(x)\n",
    "                x = x.numpy()\n",
    "                x = x.reshape(-1)\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                x += torch.normal(0, 1e-3, size=x.shape).numpy()\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                rate = torch.rand(1).numpy()[0]*2 + 7 \n",
    "                n = torch.rand(1).numpy()[0]*8 + 3 \n",
    "                x = lpf(x, sr, 2**rate, int(n//1))\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                rate = torch.rand(1).numpy()[0]*2 + 9 \n",
    "                n = torch.rand(1).numpy()[0]*8 + 3 \n",
    "                x = hpf(x, sr, 2**rate, int(n//1))\n",
    "\n",
    "            k = 0\n",
    "            while 1:\n",
    "                if torch.rand(1)>self.p_shf or k>7: break\n",
    "                mask_len = torch.randint(1, sr//100, (1,))[0].numpy()\n",
    "                start = torch.randint(0, x.shape[0]-mask_len, (1,))[0].numpy()\n",
    "                x[start:start+mask_len] = 0\n",
    "                k += 1\n",
    "\n",
    "            k = 0\n",
    "            while 1:\n",
    "                if torch.rand(1)>self.p_shf or k>7: break\n",
    "                mask_len = torch.randint(1, sr//100, (1,))[0].numpy()\n",
    "                start = torch.randint(0, x.shape[0]-mask_len, (1,))[0].numpy()\n",
    "                rev = x[start:start+mask_len]\n",
    "                rev = rev[::-1]\n",
    "                x[start:start+mask_len] = rev\n",
    "                k += 1\n",
    "                \n",
    "        batch[\"input_values\"] = x\n",
    "        \n",
    "        with processor.as_target_processor():\n",
    "            batch[\"labels\"] = processor(self.sentences[idx]).input_ids       \n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = W2v2Dataset(train, train=False)\n",
    "val_dataset = W2v2Dataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = 512#None\n",
    "    max_length_labels: Optional[int] = 512#None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorCTCWithPadding(processor=Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: PreTrainedTokenizer(name_or_path='', vocab_size=114, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'}), padding=True, max_length=512, max_length_labels=512, pad_to_multiple_of=None, pad_to_multiple_of_labels=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#\n",
    "# レーベンシュタイン距離を用いて，\n",
    "# 認識結果の誤り数を算出します．\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def calculate_error(hypothesis, reference):\n",
    "    ''' レーベンシュタイン距離を計算し，\n",
    "        置換誤り，削除誤り，挿入誤りを出力する\n",
    "    hypothesis:       認識結果(トークン毎に区切ったリスト形式)\n",
    "    reference:        正解(同上)\n",
    "    total_error:      総誤り数\n",
    "    substitute_error: 置換誤り数\n",
    "    delete_error:     削除誤り数\n",
    "    insert_error:     挿入誤り数\n",
    "    len_ref:          正解文のトークン数\n",
    "    '''\n",
    "    # 認識結果および正解系列の長さを取得\n",
    "    len_hyp = len(hypothesis)\n",
    "    len_ref = len(reference)\n",
    "\n",
    "    # 累積コスト行列を作成する\n",
    "    # 行列の各要素には，トータルコスト，\n",
    "    # 置換コスト，削除コスト，挿入コストの\n",
    "    # 累積値が辞書形式で定義される．\n",
    "    cost_matrix = [[{\"total\":0, \n",
    "                     \"substitute\":0,\n",
    "                     \"delete\":0,\n",
    "                     \"insert\":0} \\\n",
    "                     for j in range(len_ref+1)] \\\n",
    "                         for i in range(len_hyp+1)]\n",
    "\n",
    "    # 0列目と0行目の入力\n",
    "    for i in range(1, len_hyp+1):\n",
    "        # 縦方向への遷移は，削除処理を意味する\n",
    "        cost_matrix[i][0][\"delete\"] = i\n",
    "        cost_matrix[i][0][\"total\"] = i\n",
    "    for j in range(1, len_ref+1):\n",
    "        # 横方向への遷移は，挿入処理を意味する\n",
    "        cost_matrix[0][j][\"insert\"] = j\n",
    "        cost_matrix[0][j][\"total\"] = j\n",
    "\n",
    "    # 1列目と1行目以降の累積コストを計算していく\n",
    "    for i in range(1, len_hyp+1):\n",
    "        for j in range(1, len_ref+1):\n",
    "            #\n",
    "            # 各処理のコストを計算する\n",
    "            #\n",
    "            # 斜め方向の遷移時，文字が一致しない場合は，\n",
    "            # 置換処理により累積コストが1増加\n",
    "            substitute_cost = \\\n",
    "                cost_matrix[i-1][j-1][\"total\"] \\\n",
    "                + (0 if hypothesis[i-1] == reference[j-1] else 1)\n",
    "            # 縦方向の遷移時は，削除処理により累積コストが1増加\n",
    "            delete_cost = cost_matrix[i-1][j][\"total\"] + 1\n",
    "            # 横方向の遷移時は，挿入処理により累積コストが1増加\n",
    "            insert_cost = cost_matrix[i][j-1][\"total\"] + 1\n",
    "\n",
    "            # 置換処理，削除処理，挿入処理のうち，\n",
    "            # どの処理を行えば累積コストが最も小さくなるかを計算\n",
    "            cost = [substitute_cost, delete_cost, insert_cost]\n",
    "            min_index = np.argmin(cost)\n",
    "\n",
    "            if min_index == 0:\n",
    "                # 置換処理が累積コスト最小となる場合\n",
    "\n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = \\\n",
    "                    copy.copy(cost_matrix[i-1][j-1])\n",
    "                # 文字が一致しない場合は，\n",
    "                # 累積置換コストを1増加させる\n",
    "                cost_matrix[i][j][\"substitute\"] \\\n",
    "                    += (0 if hypothesis[i-1] \\\n",
    "                        == reference[j-1] else 1)\n",
    "            elif min_index == 1:\n",
    "                # 削除処理が累積コスト最小となる場合\n",
    "                \n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = copy.copy(cost_matrix[i-1][j])\n",
    "                # 累積削除コストを1増加させる\n",
    "                cost_matrix[i][j][\"delete\"] += 1\n",
    "            else:\n",
    "                # 置換処理が累積コスト最小となる場合\n",
    "                \n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = copy.copy(cost_matrix[i][j-1])\n",
    "                # 累積挿入コストを1増加させる\n",
    "                cost_matrix[i][j][\"insert\"] += 1\n",
    "\n",
    "            # 累積トータルコスト(置換+削除+挿入コスト)を更新\n",
    "            cost_matrix[i][j][\"total\"] = cost[min_index]\n",
    "\n",
    "    #\n",
    "    # エラーの数を出力する\n",
    "    # このとき，削除コストは挿入誤り，\n",
    "    # 挿入コストは削除誤りになる点に注意．\n",
    "    # (削除コストが1である\n",
    "    #    = 1文字削除しないと正解文にならない \n",
    "    #    = 認識結果は1文字分余計に挿入されている\n",
    "    #    = 挿入誤りが1である)\n",
    "    #\n",
    "\n",
    "    # 累積コスト行列の右下の要素が最終的なコストとなる．\n",
    "    total_error = cost_matrix[len_hyp][len_ref][\"total\"]\n",
    "    substitute_error = cost_matrix[len_hyp][len_ref][\"substitute\"]\n",
    "    # 削除誤り = 挿入コスト\n",
    "    delete_error = cost_matrix[len_hyp][len_ref][\"insert\"]\n",
    "    # 挿入誤り = 削除コスト\n",
    "    insert_error = cost_matrix[len_hyp][len_ref][\"delete\"]\n",
    "    \n",
    "    # 各誤り数と，正解文の文字数\n",
    "    # (誤り率を算出する際に分母として用いる)を出力\n",
    "    return (total_error, \n",
    "            substitute_error,\n",
    "            delete_error,\n",
    "            insert_error,\n",
    "            len_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtr_leven(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    for i in range(5):print(pred_str[i],'\\n',  label_str[i])\n",
    "        \n",
    "    # 各誤りの総数(エラー率算出時の分子)\n",
    "    total_err = 0\n",
    "    total_sub = 0\n",
    "    total_del = 0\n",
    "    total_ins = 0\n",
    "    # 正解文の総文字数(エラー率算出時の分母)\n",
    "    total_length = 0\n",
    "    for i in range(len(pred_str)):\n",
    "        (error, substitute, delete, insert, ref_length) \\\n",
    "                = calculate_error(pred_str[i], label_str[i])\n",
    "\n",
    "        # 総誤り数を累積する\n",
    "        total_err += error\n",
    "        total_sub += substitute\n",
    "        total_del += delete\n",
    "        total_ins += insert\n",
    "        total_length += ref_length\n",
    "        \n",
    "    err_rate = 100.0 * total_err / total_length\n",
    "    sub_rate = 100.0 * total_sub / total_length\n",
    "    del_rate = 100.0 * total_del / total_length\n",
    "    ins_rate = 100.0 * total_ins / total_length\n",
    "    return {'n_token': total_length, 'n_error': total_err, 'n_sub':total_sub, 'n_del':total_del, 'n_ins':total_ins,\n",
    "            'ter': err_rate, 'r_sub': sub_rate, 'r_del': del_rate, 'r_ins': ins_rate}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    #'facebook/wav2vec2-large-xlsr-53',\n",
    "    'charsiu/zh_w2v2_tiny_fc_10ms',\n",
    "    attention_dropout=0.2,\n",
    "    hidden_dropout=0.2,\n",
    "    feat_proj_dropout=0.2,\n",
    "    mask_time_prob=0.1,\n",
    "    layerdrop=0.2,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    diversity_loss_weight=100\n",
    ")\n",
    "\n",
    "model.lm_head = nn.Linear(384, len(processor.tokenizer))\n",
    "model.config.vocab_size=len(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Config {\n",
       "  \"_name_or_path\": \"charsiu/zh_w2v2_tiny_fc_10ms\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"adapter_kernel_size\": 3,\n",
       "  \"adapter_stride\": 2,\n",
       "  \"add_adapter\": false,\n",
       "  \"apply_spec_augment\": true,\n",
       "  \"architectures\": [\n",
       "    \"Wav2Vec2ForFrameClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.2,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classifier_proj_size\": 256,\n",
       "  \"codevector_dim\": 256,\n",
       "  \"contrastive_logits_temperature\": 0.1,\n",
       "  \"conv_bias\": false,\n",
       "  \"conv_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512\n",
       "  ],\n",
       "  \"conv_kernel\": [\n",
       "    10,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"conv_stride\": [\n",
       "    5,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    1\n",
       "  ],\n",
       "  \"ctc_loss_reduction\": \"mean\",\n",
       "  \"ctc_zero_infinity\": false,\n",
       "  \"diversity_loss_weight\": 100,\n",
       "  \"do_stable_layer_norm\": false,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feat_extract_activation\": \"gelu\",\n",
       "  \"feat_extract_norm\": \"group\",\n",
       "  \"feat_proj_dropout\": 0.2,\n",
       "  \"feat_quantizer_dropout\": 0.0,\n",
       "  \"final_dropout\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.2,\n",
       "  \"hidden_size\": 384,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"layerdrop\": 0.2,\n",
       "  \"mask_feature_length\": 10,\n",
       "  \"mask_feature_min_masks\": 0,\n",
       "  \"mask_feature_prob\": 0.0,\n",
       "  \"mask_time_length\": 10,\n",
       "  \"mask_time_min_masks\": 2,\n",
       "  \"mask_time_prob\": 0.1,\n",
       "  \"model_type\": \"wav2vec2\",\n",
       "  \"num_adapter_layers\": 3,\n",
       "  \"num_attention_heads\": 6,\n",
       "  \"num_codevector_groups\": 2,\n",
       "  \"num_codevectors_per_group\": 320,\n",
       "  \"num_conv_pos_embedding_groups\": 16,\n",
       "  \"num_conv_pos_embeddings\": 128,\n",
       "  \"num_feat_extract_layers\": 7,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"num_negatives\": 20,\n",
       "  \"output_hidden_size\": 384,\n",
       "  \"pad_token_id\": 113,\n",
       "  \"proj_codevector_dim\": 256,\n",
       "  \"tdnn_dilation\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"tdnn_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    1500\n",
       "  ],\n",
       "  \"tdnn_kernel\": [\n",
       "    5,\n",
       "    3,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.19.2\",\n",
       "  \"use_weighted_layer_sum\": false,\n",
       "  \"vocab_size\": 114,\n",
       "  \"xvector_output_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=384, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(384, 384, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=384, out_features=114, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23357554"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_ALL_WEIGHTS:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 5 * len(train)//32\n",
    "num_total_steps = num_train_epochs * len(train)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=4,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=True,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_min_num_params=0,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=4,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./wav2vec2_tiny_ja_hira/runs/Jul31_14-33-02_itsuki-System,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=50,\n",
       "optim=OptimizerNames.ADAMW_HF,\n",
       "output_dir=./wav2vec2_tiny_ja_hira,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=./wav2vec2_tiny_ja_hira,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=5,\n",
       "seed=4,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=5346,\n",
       "weight_decay=1e-05,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=f\"./wav2vec2_tiny_ja_{tgt}\",\n",
    "  group_by_length=False,\n",
    "  per_device_train_batch_size=per_device_train_batch_size,\n",
    "  gradient_accumulation_steps=32//per_device_train_batch_size,\n",
    "  per_device_eval_batch_size=per_device_train_batch_size,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  num_train_epochs=num_train_epochs,\n",
    "  fp16=False,\n",
    "  save_strategy='epoch',\n",
    "  fp16_full_eval=True,\n",
    "  logging_steps=10,\n",
    "  learning_rate=lr,\n",
    "  warmup_steps=warmup_steps,\n",
    "  save_total_limit=5,\n",
    "  weight_decay=1e-5,\n",
    "  dataloader_num_workers=4,\n",
    "  prediction_loss_only=False,\n",
    "  lr_scheduler_type='linear',\n",
    "  seed=4,\n",
    "  #eval_steps=10,\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7eff23b914f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=mtr_leven,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.feature_extractor\n",
    ")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 34215\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 53450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53450' max='53450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53450/53450 19:30:12, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>N Token</th>\n",
       "      <th>N Error</th>\n",
       "      <th>N Sub</th>\n",
       "      <th>N Del</th>\n",
       "      <th>Ter</th>\n",
       "      <th>R Sub</th>\n",
       "      <th>R Del</th>\n",
       "      <th>R Ins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.169300</td>\n",
       "      <td>3.000381</td>\n",
       "      <td>12030</td>\n",
       "      <td>11082</td>\n",
       "      <td>788</td>\n",
       "      <td>10287</td>\n",
       "      <td>92.119701</td>\n",
       "      <td>6.550291</td>\n",
       "      <td>85.511222</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.745300</td>\n",
       "      <td>1.765922</td>\n",
       "      <td>12030</td>\n",
       "      <td>5987</td>\n",
       "      <td>3197</td>\n",
       "      <td>2243</td>\n",
       "      <td>49.767249</td>\n",
       "      <td>26.575229</td>\n",
       "      <td>18.645054</td>\n",
       "      <td>4.546966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.437700</td>\n",
       "      <td>1.518175</td>\n",
       "      <td>12030</td>\n",
       "      <td>5339</td>\n",
       "      <td>2804</td>\n",
       "      <td>1942</td>\n",
       "      <td>44.380715</td>\n",
       "      <td>23.308396</td>\n",
       "      <td>16.142976</td>\n",
       "      <td>4.929343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.259600</td>\n",
       "      <td>1.416278</td>\n",
       "      <td>12030</td>\n",
       "      <td>5033</td>\n",
       "      <td>2653</td>\n",
       "      <td>1805</td>\n",
       "      <td>41.837074</td>\n",
       "      <td>22.053200</td>\n",
       "      <td>15.004156</td>\n",
       "      <td>4.779717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.202700</td>\n",
       "      <td>1.336302</td>\n",
       "      <td>12030</td>\n",
       "      <td>4753</td>\n",
       "      <td>2514</td>\n",
       "      <td>1654</td>\n",
       "      <td>39.509559</td>\n",
       "      <td>20.897756</td>\n",
       "      <td>13.748961</td>\n",
       "      <td>4.862843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.125300</td>\n",
       "      <td>1.261496</td>\n",
       "      <td>12030</td>\n",
       "      <td>4579</td>\n",
       "      <td>2414</td>\n",
       "      <td>1609</td>\n",
       "      <td>38.063175</td>\n",
       "      <td>20.066500</td>\n",
       "      <td>13.374896</td>\n",
       "      <td>4.621779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.111900</td>\n",
       "      <td>1.191241</td>\n",
       "      <td>12030</td>\n",
       "      <td>4389</td>\n",
       "      <td>2358</td>\n",
       "      <td>1479</td>\n",
       "      <td>36.483791</td>\n",
       "      <td>19.600998</td>\n",
       "      <td>12.294264</td>\n",
       "      <td>4.588529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>1.154493</td>\n",
       "      <td>12030</td>\n",
       "      <td>4191</td>\n",
       "      <td>2462</td>\n",
       "      <td>974</td>\n",
       "      <td>34.837905</td>\n",
       "      <td>20.465503</td>\n",
       "      <td>8.096426</td>\n",
       "      <td>6.275977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.950800</td>\n",
       "      <td>1.122376</td>\n",
       "      <td>12030</td>\n",
       "      <td>4112</td>\n",
       "      <td>2333</td>\n",
       "      <td>1094</td>\n",
       "      <td>34.181214</td>\n",
       "      <td>19.393184</td>\n",
       "      <td>9.093932</td>\n",
       "      <td>5.694098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>1.114096</td>\n",
       "      <td>12030</td>\n",
       "      <td>3894</td>\n",
       "      <td>2217</td>\n",
       "      <td>1043</td>\n",
       "      <td>32.369077</td>\n",
       "      <td>18.428928</td>\n",
       "      <td>8.669992</td>\n",
       "      <td>5.270158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.814900</td>\n",
       "      <td>1.069235</td>\n",
       "      <td>12030</td>\n",
       "      <td>3848</td>\n",
       "      <td>2226</td>\n",
       "      <td>899</td>\n",
       "      <td>31.986700</td>\n",
       "      <td>18.503741</td>\n",
       "      <td>7.472984</td>\n",
       "      <td>6.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>1.081349</td>\n",
       "      <td>12030</td>\n",
       "      <td>3864</td>\n",
       "      <td>2286</td>\n",
       "      <td>762</td>\n",
       "      <td>32.119701</td>\n",
       "      <td>19.002494</td>\n",
       "      <td>6.334165</td>\n",
       "      <td>6.783042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>1.019239</td>\n",
       "      <td>12030</td>\n",
       "      <td>3716</td>\n",
       "      <td>2157</td>\n",
       "      <td>867</td>\n",
       "      <td>30.889443</td>\n",
       "      <td>17.930175</td>\n",
       "      <td>7.206983</td>\n",
       "      <td>5.752286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.717300</td>\n",
       "      <td>1.046312</td>\n",
       "      <td>12030</td>\n",
       "      <td>3617</td>\n",
       "      <td>2120</td>\n",
       "      <td>845</td>\n",
       "      <td>30.066500</td>\n",
       "      <td>17.622610</td>\n",
       "      <td>7.024106</td>\n",
       "      <td>5.419784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.794200</td>\n",
       "      <td>1.028901</td>\n",
       "      <td>12030</td>\n",
       "      <td>3668</td>\n",
       "      <td>2176</td>\n",
       "      <td>693</td>\n",
       "      <td>30.490441</td>\n",
       "      <td>18.088113</td>\n",
       "      <td>5.760599</td>\n",
       "      <td>6.641729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.677100</td>\n",
       "      <td>1.030408</td>\n",
       "      <td>12030</td>\n",
       "      <td>3658</td>\n",
       "      <td>2189</td>\n",
       "      <td>543</td>\n",
       "      <td>30.407315</td>\n",
       "      <td>18.196176</td>\n",
       "      <td>4.513716</td>\n",
       "      <td>7.697423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>0.975011</td>\n",
       "      <td>12030</td>\n",
       "      <td>3576</td>\n",
       "      <td>2101</td>\n",
       "      <td>724</td>\n",
       "      <td>29.725686</td>\n",
       "      <td>17.464672</td>\n",
       "      <td>6.018288</td>\n",
       "      <td>6.242727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.757900</td>\n",
       "      <td>0.994603</td>\n",
       "      <td>12030</td>\n",
       "      <td>3549</td>\n",
       "      <td>2081</td>\n",
       "      <td>734</td>\n",
       "      <td>29.501247</td>\n",
       "      <td>17.298421</td>\n",
       "      <td>6.101413</td>\n",
       "      <td>6.101413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>0.982435</td>\n",
       "      <td>12030</td>\n",
       "      <td>3445</td>\n",
       "      <td>2045</td>\n",
       "      <td>666</td>\n",
       "      <td>28.636741</td>\n",
       "      <td>16.999169</td>\n",
       "      <td>5.536160</td>\n",
       "      <td>6.101413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>12030</td>\n",
       "      <td>3490</td>\n",
       "      <td>2057</td>\n",
       "      <td>616</td>\n",
       "      <td>29.010806</td>\n",
       "      <td>17.098919</td>\n",
       "      <td>5.120532</td>\n",
       "      <td>6.791355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.991814</td>\n",
       "      <td>12030</td>\n",
       "      <td>3456</td>\n",
       "      <td>2059</td>\n",
       "      <td>583</td>\n",
       "      <td>28.728180</td>\n",
       "      <td>17.115544</td>\n",
       "      <td>4.846218</td>\n",
       "      <td>6.766417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.980548</td>\n",
       "      <td>12030</td>\n",
       "      <td>3432</td>\n",
       "      <td>2056</td>\n",
       "      <td>646</td>\n",
       "      <td>28.528678</td>\n",
       "      <td>17.090607</td>\n",
       "      <td>5.369909</td>\n",
       "      <td>6.068163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.636900</td>\n",
       "      <td>0.960020</td>\n",
       "      <td>12030</td>\n",
       "      <td>3361</td>\n",
       "      <td>1956</td>\n",
       "      <td>700</td>\n",
       "      <td>27.938487</td>\n",
       "      <td>16.259352</td>\n",
       "      <td>5.818786</td>\n",
       "      <td>5.860349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.937921</td>\n",
       "      <td>12030</td>\n",
       "      <td>3308</td>\n",
       "      <td>1987</td>\n",
       "      <td>538</td>\n",
       "      <td>27.497922</td>\n",
       "      <td>16.517041</td>\n",
       "      <td>4.472153</td>\n",
       "      <td>6.508728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.980217</td>\n",
       "      <td>12030</td>\n",
       "      <td>3349</td>\n",
       "      <td>2000</td>\n",
       "      <td>609</td>\n",
       "      <td>27.838736</td>\n",
       "      <td>16.625104</td>\n",
       "      <td>5.062344</td>\n",
       "      <td>6.151288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.620800</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>12030</td>\n",
       "      <td>3296</td>\n",
       "      <td>1987</td>\n",
       "      <td>492</td>\n",
       "      <td>27.398171</td>\n",
       "      <td>16.517041</td>\n",
       "      <td>4.089776</td>\n",
       "      <td>6.791355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.949286</td>\n",
       "      <td>12030</td>\n",
       "      <td>3318</td>\n",
       "      <td>1934</td>\n",
       "      <td>667</td>\n",
       "      <td>27.581047</td>\n",
       "      <td>16.076475</td>\n",
       "      <td>5.544472</td>\n",
       "      <td>5.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.945147</td>\n",
       "      <td>12030</td>\n",
       "      <td>3328</td>\n",
       "      <td>1974</td>\n",
       "      <td>645</td>\n",
       "      <td>27.664173</td>\n",
       "      <td>16.408978</td>\n",
       "      <td>5.361596</td>\n",
       "      <td>5.893599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.622400</td>\n",
       "      <td>0.961083</td>\n",
       "      <td>12030</td>\n",
       "      <td>3290</td>\n",
       "      <td>1996</td>\n",
       "      <td>526</td>\n",
       "      <td>27.348296</td>\n",
       "      <td>16.591854</td>\n",
       "      <td>4.372402</td>\n",
       "      <td>6.384040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.590500</td>\n",
       "      <td>0.971619</td>\n",
       "      <td>12030</td>\n",
       "      <td>3253</td>\n",
       "      <td>1948</td>\n",
       "      <td>447</td>\n",
       "      <td>27.040732</td>\n",
       "      <td>16.192851</td>\n",
       "      <td>3.715711</td>\n",
       "      <td>7.132170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.967334</td>\n",
       "      <td>12030</td>\n",
       "      <td>3247</td>\n",
       "      <td>1921</td>\n",
       "      <td>528</td>\n",
       "      <td>26.990856</td>\n",
       "      <td>15.968412</td>\n",
       "      <td>4.389027</td>\n",
       "      <td>6.633416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.538200</td>\n",
       "      <td>0.939608</td>\n",
       "      <td>12030</td>\n",
       "      <td>3194</td>\n",
       "      <td>1907</td>\n",
       "      <td>520</td>\n",
       "      <td>26.550291</td>\n",
       "      <td>15.852037</td>\n",
       "      <td>4.322527</td>\n",
       "      <td>6.375727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.951679</td>\n",
       "      <td>12030</td>\n",
       "      <td>3219</td>\n",
       "      <td>1932</td>\n",
       "      <td>533</td>\n",
       "      <td>26.758105</td>\n",
       "      <td>16.059850</td>\n",
       "      <td>4.430590</td>\n",
       "      <td>6.267664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.944729</td>\n",
       "      <td>12030</td>\n",
       "      <td>3196</td>\n",
       "      <td>1918</td>\n",
       "      <td>496</td>\n",
       "      <td>26.566916</td>\n",
       "      <td>15.943475</td>\n",
       "      <td>4.123026</td>\n",
       "      <td>6.500416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>0.951711</td>\n",
       "      <td>12030</td>\n",
       "      <td>3195</td>\n",
       "      <td>1891</td>\n",
       "      <td>524</td>\n",
       "      <td>26.558603</td>\n",
       "      <td>15.719036</td>\n",
       "      <td>4.355777</td>\n",
       "      <td>6.483791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.939756</td>\n",
       "      <td>12030</td>\n",
       "      <td>3181</td>\n",
       "      <td>1921</td>\n",
       "      <td>506</td>\n",
       "      <td>26.442228</td>\n",
       "      <td>15.968412</td>\n",
       "      <td>4.206151</td>\n",
       "      <td>6.267664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.957973</td>\n",
       "      <td>12030</td>\n",
       "      <td>3118</td>\n",
       "      <td>1854</td>\n",
       "      <td>525</td>\n",
       "      <td>25.918537</td>\n",
       "      <td>15.411471</td>\n",
       "      <td>4.364090</td>\n",
       "      <td>6.142976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.929661</td>\n",
       "      <td>12030</td>\n",
       "      <td>3135</td>\n",
       "      <td>1864</td>\n",
       "      <td>523</td>\n",
       "      <td>26.059850</td>\n",
       "      <td>15.494597</td>\n",
       "      <td>4.347465</td>\n",
       "      <td>6.217789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.963367</td>\n",
       "      <td>12030</td>\n",
       "      <td>3114</td>\n",
       "      <td>1868</td>\n",
       "      <td>523</td>\n",
       "      <td>25.885287</td>\n",
       "      <td>15.527847</td>\n",
       "      <td>4.347465</td>\n",
       "      <td>6.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.948536</td>\n",
       "      <td>12030</td>\n",
       "      <td>3115</td>\n",
       "      <td>1844</td>\n",
       "      <td>514</td>\n",
       "      <td>25.893599</td>\n",
       "      <td>15.328346</td>\n",
       "      <td>4.272652</td>\n",
       "      <td>6.292602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.963742</td>\n",
       "      <td>12030</td>\n",
       "      <td>3123</td>\n",
       "      <td>1866</td>\n",
       "      <td>491</td>\n",
       "      <td>25.960100</td>\n",
       "      <td>15.511222</td>\n",
       "      <td>4.081463</td>\n",
       "      <td>6.367415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.490800</td>\n",
       "      <td>0.958511</td>\n",
       "      <td>12030</td>\n",
       "      <td>3098</td>\n",
       "      <td>1870</td>\n",
       "      <td>455</td>\n",
       "      <td>25.752286</td>\n",
       "      <td>15.544472</td>\n",
       "      <td>3.782211</td>\n",
       "      <td>6.425603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>12030</td>\n",
       "      <td>3095</td>\n",
       "      <td>1879</td>\n",
       "      <td>448</td>\n",
       "      <td>25.727348</td>\n",
       "      <td>15.619285</td>\n",
       "      <td>3.724023</td>\n",
       "      <td>6.384040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.969685</td>\n",
       "      <td>12030</td>\n",
       "      <td>3099</td>\n",
       "      <td>1859</td>\n",
       "      <td>461</td>\n",
       "      <td>25.760599</td>\n",
       "      <td>15.453034</td>\n",
       "      <td>3.832086</td>\n",
       "      <td>6.475478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>0.963075</td>\n",
       "      <td>12030</td>\n",
       "      <td>3116</td>\n",
       "      <td>1871</td>\n",
       "      <td>465</td>\n",
       "      <td>25.901912</td>\n",
       "      <td>15.552785</td>\n",
       "      <td>3.865337</td>\n",
       "      <td>6.483791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.962585</td>\n",
       "      <td>12030</td>\n",
       "      <td>3107</td>\n",
       "      <td>1866</td>\n",
       "      <td>452</td>\n",
       "      <td>25.827099</td>\n",
       "      <td>15.511222</td>\n",
       "      <td>3.757273</td>\n",
       "      <td>6.558603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.947319</td>\n",
       "      <td>12030</td>\n",
       "      <td>3092</td>\n",
       "      <td>1849</td>\n",
       "      <td>466</td>\n",
       "      <td>25.702411</td>\n",
       "      <td>15.369909</td>\n",
       "      <td>3.873649</td>\n",
       "      <td>6.458853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.292900</td>\n",
       "      <td>0.953414</td>\n",
       "      <td>12030</td>\n",
       "      <td>3083</td>\n",
       "      <td>1862</td>\n",
       "      <td>455</td>\n",
       "      <td>25.627598</td>\n",
       "      <td>15.477972</td>\n",
       "      <td>3.782211</td>\n",
       "      <td>6.367415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.962519</td>\n",
       "      <td>12030</td>\n",
       "      <td>3104</td>\n",
       "      <td>1861</td>\n",
       "      <td>456</td>\n",
       "      <td>25.802161</td>\n",
       "      <td>15.469659</td>\n",
       "      <td>3.790524</td>\n",
       "      <td>6.541978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.444500</td>\n",
       "      <td>0.958328</td>\n",
       "      <td>12030</td>\n",
       "      <td>3077</td>\n",
       "      <td>1839</td>\n",
       "      <td>456</td>\n",
       "      <td>25.577722</td>\n",
       "      <td>15.286783</td>\n",
       "      <td>3.790524</td>\n",
       "      <td>6.500416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "a \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "とa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "とa \n",
      " あたらしいくつをはいてでかけます\n",
      "ととたたa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-1069\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-1069/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-1069/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-1069/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ふもにいきたいととしくにa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんなくしのでこばねまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すのたささたじせんほどでれまきくよすときa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにこくきろをはいこたますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かょくといええどもことばでいつたくのはたいいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-2138\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-2138/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-2138/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-2138/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもきえさととしくにa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんくしたのでかこばんねきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すのたさはさからじせんちほどでれのきくやすときa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくきょをはいかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かそくといえどもことばでつたふのはたいしa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-3207\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-3207/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-3207/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-3207/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもいきよさここしくりa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんなくしたんのでこばんれまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すのとかさはたからじゅせんほどでれろきくやふときるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくきろをはいでますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かそくといえどもことばでつたのはいいしa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-4276\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-4276/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-4276/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-4276/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのにきさことしすa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいきんがくしんのざこばんねまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたこさはたかのじせんちほどでろをきくがふときるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "ざらしくつりょをはいてかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かそくといえうどもことばでつたえるのわだいいしa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-5345\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-5345/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-5345/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-5345/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもにきさここしみa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんなくしんのでこばんねいききまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろとこさはたなじゅせんほどでめろきくみらとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくつろをはいてかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもこばでつたえるのわだいいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-6414\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-6414/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-6414/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-6414/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-1069] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのにきえいさここしついa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんなくしんでこばんねきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさはゃかじせんちほどでめろきくややふとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくつりょをはいてけかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくとえーどもことばでつたえるのわだいしa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-7483\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-7483/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-7483/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-7483/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-2138] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのにきえよをさいこのとのしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしんのでこばんねいききまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがたかじせんちほどでいめのをおきくみややふとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくつうをはいててこうますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かつくといえいどもことばでつたえるがわでいちでa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-8552\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-8552/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-8552/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-8552/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-3207] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのみきえをさいここしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんなくしんのでこばんねきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさたかじせんちほどでめのをきくやふとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつるをはいてけかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かつくといえいどもことばでつたえるのわでいちなa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-9621\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-9621/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-9621/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-9621/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-4276] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのいきえよくさいこのこしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしがんのでこばんねいききまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさはたかなじせんきほどでめおきくややふとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくちどをはいてくますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたるのわだいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-10690\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-10690/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-10690/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-10690/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-5345] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "このににきをさいここもだしくいa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしがんのでこまんねいききまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろとかさはたかのじゅせんちほどでいめろおきくみらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつるをいてけこうますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのわだいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-11759\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-11759/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-11759/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-11759/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-6414] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもはににきえをさいこのこしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいなくしがんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさはたかのじゅせんちほどでめろおきくらやふとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくきどをはいててくういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといええどもことばでつたえるのわでいるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-12828\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-12828/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-12828/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-12828/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-7483] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのよきえをさいこのしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしかんのがこばんねきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさはしかがじゅせんちほどでめがおきくらやふとてるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくちどをいててくますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-13897\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-13897/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-13897/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-13897/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-8552] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもにいきえよくさいくろこしすいa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいんなくしかんのでこばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろとかさはしかんのじゅせんちほどでめおきくみらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくちをはいててこますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいぶもことばでつたえるのわでちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-14966\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-14966/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-14966/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-14966/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-9621] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こもにいきえをくさいここだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいなくしがんのがこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すらたかさがたかがじゅせんちほどでいれがおきくみらやふとってるるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくきよをはいててくうきますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくとえいどもことばでつたえるのわでいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-16035\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-16035/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-16035/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-16035/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-10690] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもはをににきえをくさいこのこのだしくぎいa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをんなくしかんのざこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すらたかさはたかんのじゅせんちほどでいめがおきくらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちりうをいててくますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえーどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-17104\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-17104/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-17104/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-17104/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-11759] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのをよいきえよくさいころころだしてぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしんのざこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさはひからじゅせんちほとでめがおきくなやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちるをいててくうりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちでa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-18173\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-18173/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-18173/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-18173/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-12828] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのよにきえをくさいこのこだしつa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そらたかさがしかがじゅせんちほどでるめがおきくみなやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちどをはいっててこくますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-19242\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-19242/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-19242/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-19242/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-13897] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはににきえをくさいこのこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そらたかがひかがじゅせんきほどでめがおきくみらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくてをはいててくかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-20311\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-20311/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-20311/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-20311/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-14966] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをにいきえをいさいくろこのだしくぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしかんのでんこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すらたかさがたかがじゅせんちほどでるめがおきくみらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくちるうをはいててかういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-21380\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-21380/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-21380/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-21380/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-16035] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのははよにきえをったさいこのこのだしくa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさがたかんなじゅせんちほどでめがおきくなやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくちりうをはいっててくりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-22449\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-22449/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-22449/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-22449/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-17104] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはににきえをくさいこのころだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひかいがじゅせんきほどでめがおきくみなやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちりをはいててこくりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-23518\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-23518/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-23518/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-23518/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-18173] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのをにいきえをさいくろこのだしすa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひかがじせんきほどでめがおきくらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしくちどうをはいててくますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-24587\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-24587/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-24587/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-24587/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-19242] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはよにきえよをくさいこのこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねへきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがたかがじゅせんきほとでめがおきくらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちどうをはいててこりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-25656\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-25656/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-25656/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-25656/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-20311] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのをよにきえをとさいころこのだしくいa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねへきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そらたかさがひかがじゅせんきほとでめがおおきくみらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちてをはいっっててくきますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-26725\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-26725/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-26725/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-26725/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-21380] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをよにきえをくさいころころだしてぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしがんのだこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさがたかがじゅせんきほどでめがおきくらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちどをはいっててかうりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-27794\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-27794/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-27794/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-27794/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-22449] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはおににきえをくさいころこのだしてぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしたんのでこばんねへきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひゃかいがじゅせんきほどでいめがおきくらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちてをいっててくりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-28863\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-28863/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-28863/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-28863/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-23518] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもはおににきえをくさいこのこのだしくぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがしかがじゅせんきほとでめがおきくらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "どらしにくちどをはいっっててかかういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-29932\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-29932/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-29932/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-29932/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-24587] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そもはをににきえをくさいこもこのだしくいa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そのたかさがひかやがじゅせんきほどでめがおきくらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちりうをはいっっててかうりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-31001\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-31001/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-31001/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-31001/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-25656] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをににきえをくさいころころだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひゃかいがじゅせんきほどでめがおきくんらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "やらしにくちうをいっててこりますやa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-32070\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-32070/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-32070/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-32070/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-26725] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをいにきえをとさいこのこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさはひゃかいがじゅせんちほどでめがおきくみらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "どらしにくちどをはいっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-33139\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-33139/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-33139/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-33139/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-27794] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをいにきえをきさいこのこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひかがじゅせんきほどでめがおきくにらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちうをはいっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-34208\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-34208/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-34208/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-34208/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-28863] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをいにきえをくさいこのころだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさはひゃかがじゅせんちほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちよをはいっててこますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-35277\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-35277/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-35277/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-35277/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-29932] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをににきえんをくさいこのこのだしくぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしたんのでこばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさはひかがじゅせんきほどでめがおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつるをはいっっててかますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-36346\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-36346/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-36346/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-36346/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-31001] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをいにきえをくさいころこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさはひゃかいがじゅせんちほどでめがおきくらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "よらしにくつよをはいっててこうきますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-37415\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-37415/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-37415/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-37415/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-32070] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをにいきえをとさいこのころだしくa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すまたかさがしかがじゅせんちほどでめがおきくにらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちるをはいっててこりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-38484\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-38484/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-38484/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-38484/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-33139] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはおににきえをいさいくのこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさがしかがじゅせんきほどでめがおきくみらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちるをいっててかりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-39553\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-39553/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-39553/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-39553/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-34208] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはよにきえをくさいこのこのだしてぎa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこばんねへきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すのたかさがしゃかがじゅせんきほどでめがおきくらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちどうをいっててこりますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-40622\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-40622/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-40622/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-40622/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-35277] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはおいいきえをくさいころころだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがしゃかがじゅせんちほどでめがおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちどうをいっててここういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじるa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-41691\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-41691/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-41691/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-41691/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-36346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "このはににきえをくさいころこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしたんのでこばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "そろたかさがしかがじゅせんちほどでめがおきくにらやふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちどうをいっっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-42760\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-42760/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-42760/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-42760/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-37415] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをいんきえをくさいくろこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがしゃかがじゅせんきほどでめがおきくらやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "よらしにくちるうをいっててここういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-43829\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-43829/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-43829/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-43829/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-38484] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいころこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひゃかがじゅせんきほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちでうをはいっててここうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-44898\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-44898/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-44898/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-44898/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-39553] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはをいにきえをとさいこのこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひゃかがじゅせんきほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "どらしにくちどうをはいっててここういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-45967\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-45967/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-45967/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-45967/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-40622] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはおいにきえをくさいころこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがしゃかがじゅせんちほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "どらしにくちどうをはいっててこうきいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-47036\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-47036/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-47036/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-47036/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-41691] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいくろこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしかんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひかがじゅせんきほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "よらしにくちどうをはいっててこういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-48105\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-48105/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-48105/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-48105/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-42760] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいころこのだしていa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがしゃかがじゅせんちほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちてうをはいっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-49174\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-49174/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-49174/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-49174/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-43829] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいくろこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひかがじゅせんきほどでめがおおきくにになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちでうをはいっててこういますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-50243\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-50243/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-50243/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-50243/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-44898] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいくのこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひゃかがじゅせんきほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちでうをはいっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-51312\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-51312/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-51312/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-51312/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-45967] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいくのこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこうばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがひゃかがじゅせんきほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちでうをはいっっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-52381\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-52381/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-52381/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-52381/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-47036] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そのはいにきえをくさいくのこのだしてa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふんなくしがんのでこうばんねいきまa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すろたかさがしゃかがじゅせんきほどでめがおおきくになやふとってるa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくちでうをはいっててこうりいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちだa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_hira/checkpoint-53450\n",
      "Configuration saved in ./wav2vec2_tiny_ja_hira/checkpoint-53450/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_hira/checkpoint-53450/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_hira/checkpoint-53450/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_hira/checkpoint-48105] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19h 27min 11s, sys: 11min 21s, total: 19h 38min 32s\n",
      "Wall time: 19h 30min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53450, training_loss=0.9542574843700184, metrics={'train_runtime': 70217.8027, 'train_samples_per_second': 24.363, 'train_steps_per_second': 0.761, 'total_flos': 2.0506703910796325e+19, 'train_loss': 0.9542574843700184, 'epoch': 50.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
