{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd91bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric, Audio\n",
    "import os\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from scipy import arange, around, array, linspace\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import resample\n",
    "from torchaudio import transforms\n",
    "\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af586dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_ALL_WEIGHTS = True # すべてのパラメータを学習するか最後の全結合層だけ学習するか\n",
    "lr = 1e-4 #学習率\n",
    "num_train_epochs = 50 #学習するエポック数\n",
    "per_device_train_batch_size = 8# GPU1枚あたりのバッチサイズ(32の約数)\n",
    "torch.backends.cudnn.benchmark = True # 再現性がなくなるが高速化\n",
    "tgt = 'hira' # ラベルの種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2724d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83cf3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu113'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5c0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4cabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>hira</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0161d251e9a710136aba6b9ed96572600657c1f79563b37fe36e77d84509789b879f4468eb74a199be08ea1665a62be94e61d61a47ace02acebfe396d5e34523</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_2769521...</td>\n",
       "      <td>自己が物となること、自己がなくなることではない。</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>じこがものとなることじこがなくなることではない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0161d251e9a710136aba6b9ed96572600657c1f79563b37fe36e77d84509789b879f4468eb74a199be08ea1665a62be94e61d61a47ace02acebfe396d5e34523</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_2769521...</td>\n",
       "      <td>暗証番号をど忘れしてお金を引き出せない</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>あんしょうばんごうをどわすれしておきんをひきだせない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147158368920f5b156bab36fd42423c000f7e1ceee6467a8eaac47989ee0cb1c2d231399fd7fc8ec5635</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_3068695...</td>\n",
       "      <td>それは唯心論でもなく神秘主義でもない。</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>それはゆいしんろんでもなくしんぴしゅぎでもない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147158368920f5b156bab36fd42423c000f7e1ceee6467a8eaac47989ee0cb1c2d231399fd7fc8ec5635</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_3068695...</td>\n",
       "      <td>常識は先ず行為的知識である。</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>じょうしきはまずこういてきちしきである</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147158368920f5b156bab36fd42423c000f7e1ceee6467a8eaac47989ee0cb1c2d231399fd7fc8ec5635</th>\n",
       "      <td>./data/processed_clips/common_voice_ja_3068695...</td>\n",
       "      <td>顔には何かあると書いてあるぞ？</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>かおにはなにかあるとかいてあるぞ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "client_id                                                                                               \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  ./data/processed_clips/common_voice_ja_2769521...   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  ./data/processed_clips/common_voice_ja_2769521...   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...  ./data/processed_clips/common_voice_ja_3068695...   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...  ./data/processed_clips/common_voice_ja_3068695...   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...  ./data/processed_clips/common_voice_ja_3068695...   \n",
       "\n",
       "                                                                    sentence  \\\n",
       "client_id                                                                      \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  自己が物となること、自己がなくなることではない。   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...       暗証番号をど忘れしてお金を引き出せない   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...       それは唯心論でもなく神秘主義でもない。   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...            常識は先ず行為的知識である。   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...           顔には何かあると書いてあるぞ？   \n",
       "\n",
       "                                                    up_votes  down_votes  age  \\\n",
       "client_id                                                                       \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...         2           1  NaN   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...         3           0  NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         2           1  NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         2           0  NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         2           0  NaN   \n",
       "\n",
       "                                                   gender accents locale  \\\n",
       "client_id                                                                  \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...    NaN     NaN     ja   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...    NaN     NaN     ja   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...    NaN     NaN     ja   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...    NaN     NaN     ja   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...    NaN     NaN     ja   \n",
       "\n",
       "                                                   segment  \\\n",
       "client_id                                                    \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...     NaN   \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...     NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     NaN   \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     NaN   \n",
       "\n",
       "                                                                          hira  \n",
       "client_id                                                                       \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...     じこがものとなることじこがなくなることではない  \n",
       "0161d251e9a710136aba6b9ed96572600657c1f79563b37...  あんしょうばんごうをどわすれしておきんをひきだせない  \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...     それはゆいしんろんでもなくしんぴしゅぎでもない  \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...         じょうしきはまずこういてきちしきである  \n",
       "025ba9df1f6603d5d87e104bcc48cd22ec3fafdf474c147...            かおにはなにかあるとかいてあるぞ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(f'./train_{tgt}_wav.csv', index_col=0)\n",
    "val = pd.read_csv(f'./val_{tgt}_wav.csv', index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c6b3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34215"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = val.reset_index()\n",
    "train = train.reset_index()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3063039",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='', vocab_size=114, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "tokenizer = Wav2Vec2CTCTokenizer(f\"./vocab_{tgt}.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c87d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=sr, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d81ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: PreTrainedTokenizer(name_or_path='', vocab_size=114, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ce55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "def lpf(wave, fs, fe , n):\n",
    "    nyq = fs / 2.0\n",
    "    b, a = signal.butter(1, fe/nyq, btype='low')\n",
    "    for i in range(0, n):\n",
    "        wave = signal.filtfilt(b, a, wave)\n",
    "    return wave\n",
    "\n",
    "def hpf(wave, fs, fe , n):\n",
    "    nyq = fs / 2.0\n",
    "    b, a = signal.butter(1, fe/nyq, btype='high')\n",
    "    for i in range(0, n):\n",
    "        wave = signal.filtfilt(b, a, wave)\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d1fc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stretch = torchaudio.transforms.TimeStretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3a50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2v2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, train=False, p_wav=0.75, p_shf=0.75):\n",
    "        self.df = df\n",
    "        self.pathes = df['path'].values\n",
    "        self.sentences = df[tgt].values\n",
    "        self.train = train\n",
    "        self.p_wav = p_wav\n",
    "        self.p_shf = p_shf        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate = torchaudio.load(self.pathes[idx], normalize=True)\n",
    "        batch = dict()\n",
    "        x = processor(waveform.reshape(-1), sampling_rate=sr).input_values[0]  \n",
    "        orig_shape = x.shape\n",
    "        \n",
    "        if self.train:\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                x = torch.Tensor(x)\n",
    "                rate = torch.rand(1).numpy()[0]*0.2 + 0.9 \n",
    "                x = x.reshape(1,1,1,-1)\n",
    "                x = F.interpolate(x, (1,int(rate*x.shape[-1])), mode='bilinear', align_corners=False)\n",
    "                x = x.numpy()\n",
    "                x = x.reshape(-1)\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                x = torch.Tensor(x)\n",
    "                rate = torch.rand(1).numpy()[0]*0.2 + 0.9 \n",
    "                transform = transforms.Resample(sample_rate, int(sample_rate*rate))\n",
    "                x = transform(x)\n",
    "                x = x.numpy()\n",
    "                x = x.reshape(-1)\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                x += torch.normal(0, 1e-3, size=x.shape).numpy()\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                rate = torch.rand(1).numpy()[0]*2 + 7 \n",
    "                n = torch.rand(1).numpy()[0]*8 + 3 \n",
    "                x = lpf(x, sr, 2**rate, int(n//1))\n",
    "\n",
    "            if torch.rand(1)>self.p_wav:\n",
    "                rate = torch.rand(1).numpy()[0]*2 + 9 \n",
    "                n = torch.rand(1).numpy()[0]*8 + 3 \n",
    "                x = hpf(x, sr, 2**rate, int(n//1))\n",
    "\n",
    "            k = 0\n",
    "            while 1:\n",
    "                if torch.rand(1)>self.p_shf or k>7: break\n",
    "                mask_len = torch.randint(1, sr//100, (1,))[0].numpy()\n",
    "                start = torch.randint(0, x.shape[0]-mask_len, (1,))[0].numpy()\n",
    "                x[start:start+mask_len] = 0\n",
    "                k += 1\n",
    "\n",
    "            k = 0\n",
    "            while 1:\n",
    "                if torch.rand(1)>self.p_shf or k>7: break\n",
    "                mask_len = torch.randint(1, sr//100, (1,))[0].numpy()\n",
    "                start = torch.randint(0, x.shape[0]-mask_len, (1,))[0].numpy()\n",
    "                rev = x[start:start+mask_len]\n",
    "                rev = rev[::-1]\n",
    "                x[start:start+mask_len] = rev\n",
    "                k += 1\n",
    "                \n",
    "        batch[\"input_values\"] = x\n",
    "        \n",
    "        with processor.as_target_processor():\n",
    "            batch[\"labels\"] = processor(self.sentences[idx]).input_ids       \n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = W2v2Dataset(train, train=True)\n",
    "val_dataset = W2v2Dataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00155050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = 512#None\n",
    "    max_length_labels: Optional[int] = 512#None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada8c4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorCTCWithPadding(processor=Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: PreTrainedTokenizer(name_or_path='', vocab_size=114, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'}), padding=True, max_length=512, max_length_labels=512, pad_to_multiple_of=None, pad_to_multiple_of_labels=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcae3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#\n",
    "# レーベンシュタイン距離を用いて，\n",
    "# 認識結果の誤り数を算出します．\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def calculate_error(hypothesis, reference):\n",
    "    ''' レーベンシュタイン距離を計算し，\n",
    "        置換誤り，削除誤り，挿入誤りを出力する\n",
    "    hypothesis:       認識結果(トークン毎に区切ったリスト形式)\n",
    "    reference:        正解(同上)\n",
    "    total_error:      総誤り数\n",
    "    substitute_error: 置換誤り数\n",
    "    delete_error:     削除誤り数\n",
    "    insert_error:     挿入誤り数\n",
    "    len_ref:          正解文のトークン数\n",
    "    '''\n",
    "    # 認識結果および正解系列の長さを取得\n",
    "    len_hyp = len(hypothesis)\n",
    "    len_ref = len(reference)\n",
    "\n",
    "    # 累積コスト行列を作成する\n",
    "    # 行列の各要素には，トータルコスト，\n",
    "    # 置換コスト，削除コスト，挿入コストの\n",
    "    # 累積値が辞書形式で定義される．\n",
    "    cost_matrix = [[{\"total\":0, \n",
    "                     \"substitute\":0,\n",
    "                     \"delete\":0,\n",
    "                     \"insert\":0} \\\n",
    "                     for j in range(len_ref+1)] \\\n",
    "                         for i in range(len_hyp+1)]\n",
    "\n",
    "    # 0列目と0行目の入力\n",
    "    for i in range(1, len_hyp+1):\n",
    "        # 縦方向への遷移は，削除処理を意味する\n",
    "        cost_matrix[i][0][\"delete\"] = i\n",
    "        cost_matrix[i][0][\"total\"] = i\n",
    "    for j in range(1, len_ref+1):\n",
    "        # 横方向への遷移は，挿入処理を意味する\n",
    "        cost_matrix[0][j][\"insert\"] = j\n",
    "        cost_matrix[0][j][\"total\"] = j\n",
    "\n",
    "    # 1列目と1行目以降の累積コストを計算していく\n",
    "    for i in range(1, len_hyp+1):\n",
    "        for j in range(1, len_ref+1):\n",
    "            #\n",
    "            # 各処理のコストを計算する\n",
    "            #\n",
    "            # 斜め方向の遷移時，文字が一致しない場合は，\n",
    "            # 置換処理により累積コストが1増加\n",
    "            substitute_cost = \\\n",
    "                cost_matrix[i-1][j-1][\"total\"] \\\n",
    "                + (0 if hypothesis[i-1] == reference[j-1] else 1)\n",
    "            # 縦方向の遷移時は，削除処理により累積コストが1増加\n",
    "            delete_cost = cost_matrix[i-1][j][\"total\"] + 1\n",
    "            # 横方向の遷移時は，挿入処理により累積コストが1増加\n",
    "            insert_cost = cost_matrix[i][j-1][\"total\"] + 1\n",
    "\n",
    "            # 置換処理，削除処理，挿入処理のうち，\n",
    "            # どの処理を行えば累積コストが最も小さくなるかを計算\n",
    "            cost = [substitute_cost, delete_cost, insert_cost]\n",
    "            min_index = np.argmin(cost)\n",
    "\n",
    "            if min_index == 0:\n",
    "                # 置換処理が累積コスト最小となる場合\n",
    "\n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = \\\n",
    "                    copy.copy(cost_matrix[i-1][j-1])\n",
    "                # 文字が一致しない場合は，\n",
    "                # 累積置換コストを1増加させる\n",
    "                cost_matrix[i][j][\"substitute\"] \\\n",
    "                    += (0 if hypothesis[i-1] \\\n",
    "                        == reference[j-1] else 1)\n",
    "            elif min_index == 1:\n",
    "                # 削除処理が累積コスト最小となる場合\n",
    "                \n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = copy.copy(cost_matrix[i-1][j])\n",
    "                # 累積削除コストを1増加させる\n",
    "                cost_matrix[i][j][\"delete\"] += 1\n",
    "            else:\n",
    "                # 置換処理が累積コスト最小となる場合\n",
    "                \n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = copy.copy(cost_matrix[i][j-1])\n",
    "                # 累積挿入コストを1増加させる\n",
    "                cost_matrix[i][j][\"insert\"] += 1\n",
    "\n",
    "            # 累積トータルコスト(置換+削除+挿入コスト)を更新\n",
    "            cost_matrix[i][j][\"total\"] = cost[min_index]\n",
    "\n",
    "    #\n",
    "    # エラーの数を出力する\n",
    "    # このとき，削除コストは挿入誤り，\n",
    "    # 挿入コストは削除誤りになる点に注意．\n",
    "    # (削除コストが1である\n",
    "    #    = 1文字削除しないと正解文にならない \n",
    "    #    = 認識結果は1文字分余計に挿入されている\n",
    "    #    = 挿入誤りが1である)\n",
    "    #\n",
    "\n",
    "    # 累積コスト行列の右下の要素が最終的なコストとなる．\n",
    "    total_error = cost_matrix[len_hyp][len_ref][\"total\"]\n",
    "    substitute_error = cost_matrix[len_hyp][len_ref][\"substitute\"]\n",
    "    # 削除誤り = 挿入コスト\n",
    "    delete_error = cost_matrix[len_hyp][len_ref][\"insert\"]\n",
    "    # 挿入誤り = 削除コスト\n",
    "    insert_error = cost_matrix[len_hyp][len_ref][\"delete\"]\n",
    "    \n",
    "    # 各誤り数と，正解文の文字数\n",
    "    # (誤り率を算出する際に分母として用いる)を出力\n",
    "    return (total_error, \n",
    "            substitute_error,\n",
    "            delete_error,\n",
    "            insert_error,\n",
    "            len_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02093886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtr_leven(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    for i in range(5):print(pred_str[i],'\\n',  label_str[i])\n",
    "        \n",
    "    # 各誤りの総数(エラー率算出時の分子)\n",
    "    total_err = 0\n",
    "    total_sub = 0\n",
    "    total_del = 0\n",
    "    total_ins = 0\n",
    "    # 正解文の総文字数(エラー率算出時の分母)\n",
    "    total_length = 0\n",
    "    for i in range(len(pred_str)):\n",
    "        (error, substitute, delete, insert, ref_length) \\\n",
    "                = calculate_error(pred_str[i], label_str[i])\n",
    "\n",
    "        # 総誤り数を累積する\n",
    "        total_err += error\n",
    "        total_sub += substitute\n",
    "        total_del += delete\n",
    "        total_ins += insert\n",
    "        total_length += ref_length\n",
    "        \n",
    "    err_rate = 100.0 * total_err / total_length\n",
    "    sub_rate = 100.0 * total_sub / total_length\n",
    "    del_rate = 100.0 * total_del / total_length\n",
    "    ins_rate = 100.0 * total_ins / total_length\n",
    "\n",
    "    return {'n_token': total_length, 'n_error': total_err, 'n_sub':total_sub, 'n_del':total_del, 'n_ins':total_ins,\n",
    "            'ter': err_rate, 'r_sub': sub_rate, 'r_del': del_rate, 'r_ins': ins_rate}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c31e80a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_q.weight', 'quantizer.codevectors', 'project_q.bias', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    'facebook/wav2vec2-large-xlsr-53',\n",
    "    attention_dropout=0.2,\n",
    "    hidden_dropout=0.2,\n",
    "    feat_proj_dropout=0.2,\n",
    "    mask_time_prob=0.1,\n",
    "    layerdrop=0.2,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    diversity_loss_weight=100\n",
    ")\n",
    "\n",
    "model.lm_head = nn.Linear(1024, len(processor.tokenizer))\n",
    "model.config.vocab_size=len(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1731e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Config {\n",
       "  \"_name_or_path\": \"facebook/wav2vec2-large-xlsr-53\",\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"adapter_kernel_size\": 3,\n",
       "  \"adapter_stride\": 2,\n",
       "  \"add_adapter\": false,\n",
       "  \"apply_spec_augment\": true,\n",
       "  \"architectures\": [\n",
       "    \"Wav2Vec2ForPreTraining\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.2,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classifier_proj_size\": 256,\n",
       "  \"codevector_dim\": 768,\n",
       "  \"contrastive_logits_temperature\": 0.1,\n",
       "  \"conv_bias\": true,\n",
       "  \"conv_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512\n",
       "  ],\n",
       "  \"conv_kernel\": [\n",
       "    10,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"conv_stride\": [\n",
       "    5,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"ctc_loss_reduction\": \"mean\",\n",
       "  \"ctc_zero_infinity\": false,\n",
       "  \"diversity_loss_weight\": 100,\n",
       "  \"do_stable_layer_norm\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feat_extract_activation\": \"gelu\",\n",
       "  \"feat_extract_dropout\": 0.0,\n",
       "  \"feat_extract_norm\": \"layer\",\n",
       "  \"feat_proj_dropout\": 0.2,\n",
       "  \"feat_quantizer_dropout\": 0.0,\n",
       "  \"final_dropout\": 0.0,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.2,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"layerdrop\": 0.2,\n",
       "  \"mask_channel_length\": 10,\n",
       "  \"mask_channel_min_space\": 1,\n",
       "  \"mask_channel_other\": 0.0,\n",
       "  \"mask_channel_prob\": 0.0,\n",
       "  \"mask_channel_selection\": \"static\",\n",
       "  \"mask_feature_length\": 10,\n",
       "  \"mask_feature_min_masks\": 0,\n",
       "  \"mask_feature_prob\": 0.0,\n",
       "  \"mask_time_length\": 10,\n",
       "  \"mask_time_min_masks\": 2,\n",
       "  \"mask_time_min_space\": 1,\n",
       "  \"mask_time_other\": 0.0,\n",
       "  \"mask_time_prob\": 0.1,\n",
       "  \"mask_time_selection\": \"static\",\n",
       "  \"model_type\": \"wav2vec2\",\n",
       "  \"num_adapter_layers\": 3,\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_codevector_groups\": 2,\n",
       "  \"num_codevectors_per_group\": 320,\n",
       "  \"num_conv_pos_embedding_groups\": 16,\n",
       "  \"num_conv_pos_embeddings\": 128,\n",
       "  \"num_feat_extract_layers\": 7,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_negatives\": 100,\n",
       "  \"output_hidden_size\": 1024,\n",
       "  \"pad_token_id\": 113,\n",
       "  \"proj_codevector_dim\": 768,\n",
       "  \"tdnn_dilation\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"tdnn_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    1500\n",
       "  ],\n",
       "  \"tdnn_kernel\": [\n",
       "    5,\n",
       "    3,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"use_weighted_layer_sum\": false,\n",
       "  \"vocab_size\": 114,\n",
       "  \"xvector_output_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77e438a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=114, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deaec822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315555570"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47658607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_ALL_WEIGHTS:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "801b8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1466b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 5 * len(train)//32\n",
    "num_total_steps = num_train_epochs * len(train)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "815ae6c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=4,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=True,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_min_num_params=0,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=4,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./wav2vec2_xlsr_ja_hira/runs/Jul30_22-27-57_itsuki-Z490-S01,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=50,\n",
       "optim=OptimizerNames.ADAMW_HF,\n",
       "output_dir=./wav2vec2_xlsr_ja_hira,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=./wav2vec2_xlsr_ja_hira,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=5,\n",
       "seed=4,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=5346,\n",
       "weight_decay=1e-05,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=f\"./wav2vec2_xlsr_ja_{tgt}\",\n",
    "  group_by_length=False,\n",
    "  per_device_train_batch_size=per_device_train_batch_size,\n",
    "  gradient_accumulation_steps=32//per_device_train_batch_size,\n",
    "  per_device_eval_batch_size=per_device_train_batch_size,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  num_train_epochs=num_train_epochs,\n",
    "  fp16=False,\n",
    "  save_strategy='epoch',\n",
    "  fp16_full_eval=True,\n",
    "  logging_steps=10,\n",
    "  learning_rate=lr,\n",
    "  warmup_steps=warmup_steps,\n",
    "  save_total_limit=5,\n",
    "  weight_decay=1e-5,\n",
    "  dataloader_num_workers=4,\n",
    "  prediction_loss_only=False,\n",
    "  lr_scheduler_type='linear',\n",
    "  seed=4,\n",
    "  #eval_steps=10,\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd9695f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7f9c800a39d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=mtr_leven,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.feature_extractor\n",
    ")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0d8c2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8873632e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 34215\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 53450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53450' max='53450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [53450/53450 90:19:27, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Er</th>\n",
       "      <th>Sr</th>\n",
       "      <th>Dr</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.149300</td>\n",
       "      <td>4.481318</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.089776</td>\n",
       "      <td>95.910224</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.077200</td>\n",
       "      <td>4.105532</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.089776</td>\n",
       "      <td>95.910224</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.594100</td>\n",
       "      <td>3.127913</td>\n",
       "      <td>98.004988</td>\n",
       "      <td>4.380715</td>\n",
       "      <td>93.615960</td>\n",
       "      <td>0.008313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.056100</td>\n",
       "      <td>1.017686</td>\n",
       "      <td>26.716542</td>\n",
       "      <td>15.419784</td>\n",
       "      <td>2.967581</td>\n",
       "      <td>8.329177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.746900</td>\n",
       "      <td>0.831252</td>\n",
       "      <td>22.593516</td>\n",
       "      <td>12.801330</td>\n",
       "      <td>2.302577</td>\n",
       "      <td>7.489609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.537700</td>\n",
       "      <td>0.677111</td>\n",
       "      <td>20.689942</td>\n",
       "      <td>11.363259</td>\n",
       "      <td>1.961762</td>\n",
       "      <td>7.364921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.592100</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>20.315877</td>\n",
       "      <td>11.197007</td>\n",
       "      <td>1.670823</td>\n",
       "      <td>7.448047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.667006</td>\n",
       "      <td>19.152120</td>\n",
       "      <td>10.083126</td>\n",
       "      <td>1.413134</td>\n",
       "      <td>7.655860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.491700</td>\n",
       "      <td>0.599228</td>\n",
       "      <td>18.869493</td>\n",
       "      <td>9.883624</td>\n",
       "      <td>1.404821</td>\n",
       "      <td>7.581047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.472100</td>\n",
       "      <td>0.589231</td>\n",
       "      <td>17.988362</td>\n",
       "      <td>9.625935</td>\n",
       "      <td>1.396509</td>\n",
       "      <td>6.965919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.385100</td>\n",
       "      <td>0.586937</td>\n",
       "      <td>17.655860</td>\n",
       "      <td>8.944306</td>\n",
       "      <td>1.579385</td>\n",
       "      <td>7.132170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.390900</td>\n",
       "      <td>0.587278</td>\n",
       "      <td>17.331671</td>\n",
       "      <td>8.711554</td>\n",
       "      <td>1.313383</td>\n",
       "      <td>7.306733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.285600</td>\n",
       "      <td>0.513236</td>\n",
       "      <td>16.650042</td>\n",
       "      <td>8.403990</td>\n",
       "      <td>1.429759</td>\n",
       "      <td>6.816293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.271900</td>\n",
       "      <td>0.535232</td>\n",
       "      <td>16.965919</td>\n",
       "      <td>8.487116</td>\n",
       "      <td>1.521197</td>\n",
       "      <td>6.957606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.252500</td>\n",
       "      <td>0.466887</td>\n",
       "      <td>15.677473</td>\n",
       "      <td>7.880299</td>\n",
       "      <td>1.579385</td>\n",
       "      <td>6.217789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.209000</td>\n",
       "      <td>0.520418</td>\n",
       "      <td>15.835411</td>\n",
       "      <td>7.913549</td>\n",
       "      <td>1.479634</td>\n",
       "      <td>6.442228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.242300</td>\n",
       "      <td>0.479813</td>\n",
       "      <td>17.040732</td>\n",
       "      <td>7.788861</td>\n",
       "      <td>1.695761</td>\n",
       "      <td>7.556110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.245400</td>\n",
       "      <td>0.445808</td>\n",
       "      <td>15.411471</td>\n",
       "      <td>7.614298</td>\n",
       "      <td>1.637573</td>\n",
       "      <td>6.159601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.159100</td>\n",
       "      <td>0.455328</td>\n",
       "      <td>15.735661</td>\n",
       "      <td>7.788861</td>\n",
       "      <td>1.720698</td>\n",
       "      <td>6.226101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.188000</td>\n",
       "      <td>0.461961</td>\n",
       "      <td>15.835411</td>\n",
       "      <td>7.448047</td>\n",
       "      <td>1.554447</td>\n",
       "      <td>6.832918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.088200</td>\n",
       "      <td>0.434358</td>\n",
       "      <td>15.062344</td>\n",
       "      <td>7.281796</td>\n",
       "      <td>1.670823</td>\n",
       "      <td>6.109726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.104500</td>\n",
       "      <td>0.429137</td>\n",
       "      <td>14.896093</td>\n",
       "      <td>7.281796</td>\n",
       "      <td>1.562760</td>\n",
       "      <td>6.051538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.208000</td>\n",
       "      <td>0.407568</td>\n",
       "      <td>14.862843</td>\n",
       "      <td>7.015794</td>\n",
       "      <td>1.762261</td>\n",
       "      <td>6.084788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.107200</td>\n",
       "      <td>0.406476</td>\n",
       "      <td>14.413965</td>\n",
       "      <td>6.990856</td>\n",
       "      <td>1.471322</td>\n",
       "      <td>5.951787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.172800</td>\n",
       "      <td>0.412606</td>\n",
       "      <td>14.638404</td>\n",
       "      <td>6.957606</td>\n",
       "      <td>1.529510</td>\n",
       "      <td>6.151288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.196700</td>\n",
       "      <td>0.422834</td>\n",
       "      <td>14.779717</td>\n",
       "      <td>7.140482</td>\n",
       "      <td>1.404821</td>\n",
       "      <td>6.234414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>14.098088</td>\n",
       "      <td>6.616791</td>\n",
       "      <td>1.562760</td>\n",
       "      <td>5.918537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.064100</td>\n",
       "      <td>0.399891</td>\n",
       "      <td>14.181214</td>\n",
       "      <td>6.633416</td>\n",
       "      <td>1.695761</td>\n",
       "      <td>5.852037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.241100</td>\n",
       "      <td>0.403777</td>\n",
       "      <td>14.380715</td>\n",
       "      <td>6.807980</td>\n",
       "      <td>1.471322</td>\n",
       "      <td>6.101413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.206900</td>\n",
       "      <td>0.395137</td>\n",
       "      <td>14.555278</td>\n",
       "      <td>6.625104</td>\n",
       "      <td>1.679135</td>\n",
       "      <td>6.251039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.000700</td>\n",
       "      <td>0.396326</td>\n",
       "      <td>13.848712</td>\n",
       "      <td>6.625104</td>\n",
       "      <td>1.521197</td>\n",
       "      <td>5.702411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>13.657523</td>\n",
       "      <td>6.201164</td>\n",
       "      <td>1.321696</td>\n",
       "      <td>6.134663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.097500</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>13.574397</td>\n",
       "      <td>6.317539</td>\n",
       "      <td>1.612635</td>\n",
       "      <td>5.644223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.022900</td>\n",
       "      <td>0.382740</td>\n",
       "      <td>13.499584</td>\n",
       "      <td>6.259352</td>\n",
       "      <td>1.363259</td>\n",
       "      <td>5.876974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.063200</td>\n",
       "      <td>0.382377</td>\n",
       "      <td>13.798836</td>\n",
       "      <td>6.442228</td>\n",
       "      <td>1.438071</td>\n",
       "      <td>5.918537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.001200</td>\n",
       "      <td>0.393785</td>\n",
       "      <td>14.164589</td>\n",
       "      <td>6.633416</td>\n",
       "      <td>1.363259</td>\n",
       "      <td>6.167914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.988200</td>\n",
       "      <td>0.382227</td>\n",
       "      <td>13.599335</td>\n",
       "      <td>6.275977</td>\n",
       "      <td>1.421446</td>\n",
       "      <td>5.901912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.085000</td>\n",
       "      <td>0.380598</td>\n",
       "      <td>13.848712</td>\n",
       "      <td>6.392352</td>\n",
       "      <td>1.363259</td>\n",
       "      <td>6.093101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.382513</td>\n",
       "      <td>13.740648</td>\n",
       "      <td>6.134663</td>\n",
       "      <td>1.354946</td>\n",
       "      <td>6.251039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.023500</td>\n",
       "      <td>0.385566</td>\n",
       "      <td>13.773899</td>\n",
       "      <td>6.267664</td>\n",
       "      <td>1.371571</td>\n",
       "      <td>6.134663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.022100</td>\n",
       "      <td>0.379123</td>\n",
       "      <td>13.649210</td>\n",
       "      <td>6.151288</td>\n",
       "      <td>1.404821</td>\n",
       "      <td>6.093101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.067900</td>\n",
       "      <td>0.374867</td>\n",
       "      <td>13.557772</td>\n",
       "      <td>6.101413</td>\n",
       "      <td>1.429759</td>\n",
       "      <td>6.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.006100</td>\n",
       "      <td>0.375340</td>\n",
       "      <td>13.599335</td>\n",
       "      <td>6.118038</td>\n",
       "      <td>1.454697</td>\n",
       "      <td>6.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.974500</td>\n",
       "      <td>0.373120</td>\n",
       "      <td>13.399834</td>\n",
       "      <td>6.068163</td>\n",
       "      <td>1.396509</td>\n",
       "      <td>5.935162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.039700</td>\n",
       "      <td>0.371410</td>\n",
       "      <td>13.366584</td>\n",
       "      <td>6.101413</td>\n",
       "      <td>1.396509</td>\n",
       "      <td>5.868662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.066800</td>\n",
       "      <td>0.367627</td>\n",
       "      <td>13.283458</td>\n",
       "      <td>5.985037</td>\n",
       "      <td>1.438071</td>\n",
       "      <td>5.860349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.995300</td>\n",
       "      <td>0.362361</td>\n",
       "      <td>13.391521</td>\n",
       "      <td>6.026600</td>\n",
       "      <td>1.504572</td>\n",
       "      <td>5.860349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.038700</td>\n",
       "      <td>0.366267</td>\n",
       "      <td>13.275145</td>\n",
       "      <td>5.960100</td>\n",
       "      <td>1.388196</td>\n",
       "      <td>5.926850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.011600</td>\n",
       "      <td>0.363825</td>\n",
       "      <td>13.325021</td>\n",
       "      <td>6.009975</td>\n",
       "      <td>1.354946</td>\n",
       "      <td>5.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.985300</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>13.424771</td>\n",
       "      <td>5.926850</td>\n",
       "      <td>1.388196</td>\n",
       "      <td>6.109726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "a \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "a \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "a \n",
      " あたらしいくつをはいてでかけます\n",
      "a \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-1069\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-1069/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-1069/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-1069/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "a \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "a \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "a \n",
      " あたらしいくつをはいてでかけます\n",
      "a \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-2138\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-2138/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-2138/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-2138/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "a \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "たa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たa \n",
      " あたらしいくつをはいてでかけます\n",
      "a \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-3207\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-3207/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-3207/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-3207/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼをおむにきでんよけさいこのころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいつおうなくしたんのでこうばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはゃからなじょつせんちょほどでめがおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらんしにくつよをはいてげかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かそくとえいどもことばでつたえるのはだいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-4276\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-4276/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-4276/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-4276/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼをおむにきげんおけさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいすをなくしたんのでこうばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せまたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつおをはいてげかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-5345\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-5345/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-5345/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-5345/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおむにきねんよきさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこうばんねいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつろをはいてでかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのがだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-6414\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-6414/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-6414/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-6414/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-1069] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼーはおむにきげんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこうばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややくとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつろをはいてけかんけいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-7483\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-7483/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-7483/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-7483/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-2138] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおむにきねんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたーんのでこうばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつろをはいってでかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-8552\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-8552/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-8552/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-8552/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-3207] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおむにきげんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしかんのでこうばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつろをはいてでかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいちa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-9621\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-9621/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-9621/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-9621/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-4276] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおむにきねんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつろをはいてでかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわたいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-10690\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-10690/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-10690/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-10690/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-5345] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおもにきげんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこうばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつよをはいてでかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわたいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-11759\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-11759/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-11759/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-11759/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-6414] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおもにきげんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしゅたんのでこうばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつるをはいてでかんけいますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-12828\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-12828/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-12828/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-12828/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-7483] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおむにきれんおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこーばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつよをはいててかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-13897\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-13897/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-13897/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-13897/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-8552] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおもにきげんよくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこばんねへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "すのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつよをはいいててかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえいどもことばでつたえるのわだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-14966\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-14966/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-14966/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-14966/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-9621] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきれんよくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふうなくしたんのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつよをいててかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-16035\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-16035/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-16035/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-16035/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-10690] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおもにきねんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふうなくしたんのでこーばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつよをいっってでかんけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-17104\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-17104/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-17104/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-17104/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-11759] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおもにきねんおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしにくつをいててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-18173\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-18173/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-18173/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-18173/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-12828] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしたんのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくつよをいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-19242\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-19242/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-19242/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-19242/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-13897] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねいおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふーなくしたんのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんじほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしにくつよをいってでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-20311\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-20311/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-20311/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-20311/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-14966] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だだしにくつよをはいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-21380\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-21380/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-21380/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-21380/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-16035] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしにくつよをいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-22449\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-22449/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-22449/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-22449/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-17104] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねいおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-23518\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-23518/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-23518/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-23518/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-18173] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねんおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-24587\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-24587/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-24587/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-24587/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-19242] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねいおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふおなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくつをいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-25656\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-25656/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-25656/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-25656/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-20311] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねいおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅつせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-26725\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-26725/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-26725/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-26725/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-21380] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおむにきねいおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくいややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "だらしいくつよをはいってでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-27794\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-27794/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-27794/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-27794/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-22449] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-28863\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-28863/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-28863/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-28863/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-23518] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねいおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいってでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-29932\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-29932/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-29932/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-29932/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-24587] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼうはおもにきげんへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふおなくしたんのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつよをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-31001\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-31001/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-31001/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-31001/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-25656] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむりきねんへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふおなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-32070\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-32070/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-32070/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-32070/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-26725] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねいよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-33139\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-33139/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-33139/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-33139/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-27794] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおむにきねんようくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-34208\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-34208/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-34208/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-34208/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-28863] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-35277\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-35277/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-35277/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-35277/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-29932] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-36346\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-36346/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-36346/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-36346/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-31001] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんへおくさいころころがしているそそそa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいてでかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-37415\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-37415/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-37415/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-37415/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-32070] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきんんおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-38484\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-38484/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-38484/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-38484/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-33139] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんへよくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅっせんちほどでめがおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-39553\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-39553/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-39553/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-39553/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-34208] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたんのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-40622\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-40622/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-40622/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-40622/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-35277] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきげんへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-41691\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-41691/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-41691/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-41691/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-36346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんへおくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-42760\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-42760/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-42760/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-42760/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-37415] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきんんへおくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-43829\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-43829/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-43829/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-43829/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-38484] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきんんおくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-44898\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-44898/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-44898/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-44898/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-39553] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきんんおくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふおなくしたんのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-45967\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-45967/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-45967/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-45967/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-40622] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねへおくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-47036\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-47036/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-47036/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-47036/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-41691] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねへおくさいほろころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-48105\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-48105/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-48105/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-48105/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-42760] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-49174\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-49174/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-49174/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-49174/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-43829] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきんんおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-50243\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-50243/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-50243/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-50243/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-44898] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくななじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-51312\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-51312/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-51312/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-51312/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-45967] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねへおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-52381\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-52381/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-52381/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-52381/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-47036] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そぼはおもにきねんおおくさいころころがしているa \n",
      " そぼはおおむねきげんよくさいころをころがしている\n",
      "さいふをなくしたのでこうばんへへいきますa \n",
      " さいふをなくしたのでこうばんへいきます\n",
      "せのたかさはひゃくらなじゅうせんちほどでめがおおきくややふとっているa \n",
      " せのたかさはいちしち〇せんちほどでめがおおきくややふとっている\n",
      "たらしいくつをはいっててかけますa \n",
      " あたらしいくつをはいてでかけます\n",
      "かぞくといえどもことばでつたえるのはだいじa \n",
      " かぞくといえどもことばでつたえるのはだいじ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_xlsr_ja_hira/checkpoint-53450\n",
      "Configuration saved in ./wav2vec2_xlsr_ja_hira/checkpoint-53450/config.json\n",
      "Model weights saved in ./wav2vec2_xlsr_ja_hira/checkpoint-53450/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_xlsr_ja_hira/checkpoint-53450/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_xlsr_ja_hira/checkpoint-48105] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 1h 51min 2s, sys: 2h 45min 4s, total: 1d 4h 36min 7s\n",
      "Wall time: 3d 18h 19min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53450, training_loss=1.7673370755109081, metrics={'train_runtime': 325182.8395, 'train_samples_per_second': 5.261, 'train_steps_per_second': 0.164, 'total_flos': 3.8871539202226966e+20, 'train_loss': 1.7673370755109081, 'epoch': 50.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0998ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
