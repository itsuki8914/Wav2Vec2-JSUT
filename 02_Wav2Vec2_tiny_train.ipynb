{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd91bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric, Audio\n",
    "import os\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af586dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_ALL_WEIGHTS = True # すべてのパラメータを学習するか最後の全結合層だけ学習するか\n",
    "lr = 1e-4 #学習率\n",
    "num_train_epochs = 50 #学習するエポック数\n",
    "per_device_train_batch_size = 16 # GPU1枚あたりのバッチサイズ(32の約数)\n",
    "torch.backends.cudnn.benchmark = True # 再現性がなくなるが高速化\n",
    "tgt = 'roman' # ラベルの種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cf3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5c0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4cabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>char</th>\n",
       "      <th>hira</th>\n",
       "      <th>phone</th>\n",
       "      <th>roman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>./data/wav/BASIC5000_0251.wav</td>\n",
       "      <td>演 奏 会 の 切 符 は 当 事 務 所 で 販 売 し て い ま す</td>\n",
       "      <td>え ん そ ー か い の き っ ぷ わ と ー じ む し ょ で は ん ば い し ...</td>\n",
       "      <td>e   N   s   o   o   k   a   i   n   o   k   i ...</td>\n",
       "      <td>ensookainokippuwatoojimushodehanbaishiteimasu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>./data/wav/BASIC5000_0252.wav</td>\n",
       "      <td>市 場 価 格 の 暴 落 で 一 文 無 し に な っ て し ま っ た</td>\n",
       "      <td>し じ ょ ー か か く の ぼ ー ら く で い ち も ん な し に な っ て ...</td>\n",
       "      <td>s h   i   j   o   o   k   a   k   a   k   u   ...</td>\n",
       "      <td>shijookakakunoboorakudeichimonnashininatteshim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>./data/wav/BASIC5000_0253.wav</td>\n",
       "      <td>女 と い う も の は 何 で も お 金 に 換 算 し て 考 え る</td>\n",
       "      <td>お ん な と ゆ ー も の わ な ん で も お か ね に か ん ざ ん し て ...</td>\n",
       "      <td>o   N   n   a   t   o   y   u   u   m   o   n ...</td>\n",
       "      <td>onnatoyuumonowanandemookanenikanzanshitekangaeru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>./data/wav/BASIC5000_0254.wav</td>\n",
       "      <td>女 は テ ー ブ ル の ナ イ フ に 手 を 伸 ば し た</td>\n",
       "      <td>お ん な わ て ー ぶ る の な い ふ に て を の ば し た</td>\n",
       "      <td>o   N   n   a   w   a   t   e   e   b   u   r ...</td>\n",
       "      <td>onnawateeburunonaifunitewonobashita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>./data/wav/BASIC5000_0255.wav</td>\n",
       "      <td>女 の 子 は い い 服 を 見 せ び ら か す の が 好 き だ</td>\n",
       "      <td>お ん な の こ わ い い ふ く を み せ び ら か す の が す き だ</td>\n",
       "      <td>o   N   n   a   n   o   k   o   w   a   p a u ...</td>\n",
       "      <td>onnanokowaiifukuwomisebirakasunogasukida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filepath                                     char  \\\n",
       "250  ./data/wav/BASIC5000_0251.wav    演 奏 会 の 切 符 は 当 事 務 所 で 販 売 し て い ま す   \n",
       "251  ./data/wav/BASIC5000_0252.wav  市 場 価 格 の 暴 落 で 一 文 無 し に な っ て し ま っ た   \n",
       "252  ./data/wav/BASIC5000_0253.wav  女 と い う も の は 何 で も お 金 に 換 算 し て 考 え る   \n",
       "253  ./data/wav/BASIC5000_0254.wav        女 は テ ー ブ ル の ナ イ フ に 手 を 伸 ば し た   \n",
       "254  ./data/wav/BASIC5000_0255.wav    女 の 子 は い い 服 を 見 せ び ら か す の が 好 き だ   \n",
       "\n",
       "                                                  hira  \\\n",
       "250  え ん そ ー か い の き っ ぷ わ と ー じ む し ょ で は ん ば い し ...   \n",
       "251  し じ ょ ー か か く の ぼ ー ら く で い ち も ん な し に な っ て ...   \n",
       "252  お ん な と ゆ ー も の わ な ん で も お か ね に か ん ざ ん し て ...   \n",
       "253              お ん な わ て ー ぶ る の な い ふ に て を の ば し た   \n",
       "254        お ん な の こ わ い い ふ く を み せ び ら か す の が す き だ   \n",
       "\n",
       "                                                 phone  \\\n",
       "250  e   N   s   o   o   k   a   i   n   o   k   i ...   \n",
       "251  s h   i   j   o   o   k   a   k   a   k   u   ...   \n",
       "252  o   N   n   a   t   o   y   u   u   m   o   n ...   \n",
       "253  o   N   n   a   w   a   t   e   e   b   u   r ...   \n",
       "254  o   N   n   a   n   o   k   o   w   a   p a u ...   \n",
       "\n",
       "                                                 roman  \n",
       "250      ensookainokippuwatoojimushodehanbaishiteimasu  \n",
       "251  shijookakakunoboorakudeichimonnashininatteshim...  \n",
       "252   onnatoyuumonowanandemookanenikanzanshitekangaeru  \n",
       "253                onnawateeburunonaifunitewonobashita  \n",
       "254           onnanokowaiifukuwomisebirakasunogasukida  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(f'./train_{tgt}.csv', index_col=0)\n",
    "val = pd.read_csv(f'./val_{tgt}.csv', index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c6b3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = val.reset_index()\n",
    "train = train.reset_index()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3063039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='', vocab_size=26, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(f\"./vocab_{tgt}.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c87d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=sr, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d81ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: PreTrainedTokenizer(name_or_path='', vocab_size=26, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3a50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2v2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.pathes = df['filepath'].values\n",
    "        self.sentences = df[tgt].values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate = torchaudio.load(self.pathes[idx])\n",
    "        batch = dict()\n",
    "        batch[\"input_values\"] = processor(waveform.reshape(-1), sampling_rate=sr).input_values[0]  \n",
    "        with processor.as_target_processor():\n",
    "            batch[\"labels\"] = processor(self.sentences[idx]).input_ids       \n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = W2v2Dataset(train)\n",
    "val_dataset = W2v2Dataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00155050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada8c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcae3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#\n",
    "# レーベンシュタイン距離を用いて，\n",
    "# 認識結果の誤り数を算出します．\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def calculate_error(hypothesis, reference):\n",
    "    ''' レーベンシュタイン距離を計算し，\n",
    "        置換誤り，削除誤り，挿入誤りを出力する\n",
    "    hypothesis:       認識結果(トークン毎に区切ったリスト形式)\n",
    "    reference:        正解(同上)\n",
    "    total_error:      総誤り数\n",
    "    substitute_error: 置換誤り数\n",
    "    delete_error:     削除誤り数\n",
    "    insert_error:     挿入誤り数\n",
    "    len_ref:          正解文のトークン数\n",
    "    '''\n",
    "    # 認識結果および正解系列の長さを取得\n",
    "    len_hyp = len(hypothesis)\n",
    "    len_ref = len(reference)\n",
    "\n",
    "    # 累積コスト行列を作成する\n",
    "    # 行列の各要素には，トータルコスト，\n",
    "    # 置換コスト，削除コスト，挿入コストの\n",
    "    # 累積値が辞書形式で定義される．\n",
    "    cost_matrix = [[{\"total\":0, \n",
    "                     \"substitute\":0,\n",
    "                     \"delete\":0,\n",
    "                     \"insert\":0} \\\n",
    "                     for j in range(len_ref+1)] \\\n",
    "                         for i in range(len_hyp+1)]\n",
    "\n",
    "    # 0列目と0行目の入力\n",
    "    for i in range(1, len_hyp+1):\n",
    "        # 縦方向への遷移は，削除処理を意味する\n",
    "        cost_matrix[i][0][\"delete\"] = i\n",
    "        cost_matrix[i][0][\"total\"] = i\n",
    "    for j in range(1, len_ref+1):\n",
    "        # 横方向への遷移は，挿入処理を意味する\n",
    "        cost_matrix[0][j][\"insert\"] = j\n",
    "        cost_matrix[0][j][\"total\"] = j\n",
    "\n",
    "    # 1列目と1行目以降の累積コストを計算していく\n",
    "    for i in range(1, len_hyp+1):\n",
    "        for j in range(1, len_ref+1):\n",
    "            #\n",
    "            # 各処理のコストを計算する\n",
    "            #\n",
    "            # 斜め方向の遷移時，文字が一致しない場合は，\n",
    "            # 置換処理により累積コストが1増加\n",
    "            substitute_cost = \\\n",
    "                cost_matrix[i-1][j-1][\"total\"] \\\n",
    "                + (0 if hypothesis[i-1] == reference[j-1] else 1)\n",
    "            # 縦方向の遷移時は，削除処理により累積コストが1増加\n",
    "            delete_cost = cost_matrix[i-1][j][\"total\"] + 1\n",
    "            # 横方向の遷移時は，挿入処理により累積コストが1増加\n",
    "            insert_cost = cost_matrix[i][j-1][\"total\"] + 1\n",
    "\n",
    "            # 置換処理，削除処理，挿入処理のうち，\n",
    "            # どの処理を行えば累積コストが最も小さくなるかを計算\n",
    "            cost = [substitute_cost, delete_cost, insert_cost]\n",
    "            min_index = np.argmin(cost)\n",
    "\n",
    "            if min_index == 0:\n",
    "                # 置換処理が累積コスト最小となる場合\n",
    "\n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = \\\n",
    "                    copy.copy(cost_matrix[i-1][j-1])\n",
    "                # 文字が一致しない場合は，\n",
    "                # 累積置換コストを1増加させる\n",
    "                cost_matrix[i][j][\"substitute\"] \\\n",
    "                    += (0 if hypothesis[i-1] \\\n",
    "                        == reference[j-1] else 1)\n",
    "            elif min_index == 1:\n",
    "                # 削除処理が累積コスト最小となる場合\n",
    "                \n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = copy.copy(cost_matrix[i-1][j])\n",
    "                # 累積削除コストを1増加させる\n",
    "                cost_matrix[i][j][\"delete\"] += 1\n",
    "            else:\n",
    "                # 置換処理が累積コスト最小となる場合\n",
    "                \n",
    "                # 遷移元の累積コスト情報をコピー\n",
    "                cost_matrix[i][j] = copy.copy(cost_matrix[i][j-1])\n",
    "                # 累積挿入コストを1増加させる\n",
    "                cost_matrix[i][j][\"insert\"] += 1\n",
    "\n",
    "            # 累積トータルコスト(置換+削除+挿入コスト)を更新\n",
    "            cost_matrix[i][j][\"total\"] = cost[min_index]\n",
    "\n",
    "    #\n",
    "    # エラーの数を出力する\n",
    "    # このとき，削除コストは挿入誤り，\n",
    "    # 挿入コストは削除誤りになる点に注意．\n",
    "    # (削除コストが1である\n",
    "    #    = 1文字削除しないと正解文にならない \n",
    "    #    = 認識結果は1文字分余計に挿入されている\n",
    "    #    = 挿入誤りが1である)\n",
    "    #\n",
    "\n",
    "    # 累積コスト行列の右下の要素が最終的なコストとなる．\n",
    "    total_error = cost_matrix[len_hyp][len_ref][\"total\"]\n",
    "    substitute_error = cost_matrix[len_hyp][len_ref][\"substitute\"]\n",
    "    # 削除誤り = 挿入コスト\n",
    "    delete_error = cost_matrix[len_hyp][len_ref][\"insert\"]\n",
    "    # 挿入誤り = 削除コスト\n",
    "    insert_error = cost_matrix[len_hyp][len_ref][\"delete\"]\n",
    "    \n",
    "    # 各誤り数と，正解文の文字数\n",
    "    # (誤り率を算出する際に分母として用いる)を出力\n",
    "    return (total_error, \n",
    "            substitute_error,\n",
    "            delete_error,\n",
    "            insert_error,\n",
    "            len_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02093886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtr_leven(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    for i in range(5):print(pred_str[i],'\\n',  label_str[i])\n",
    "        \n",
    "    # 各誤りの総数(エラー率算出時の分子)\n",
    "    total_err = 0\n",
    "    total_sub = 0\n",
    "    total_del = 0\n",
    "    total_ins = 0\n",
    "    # 正解文の総文字数(エラー率算出時の分母)\n",
    "    total_length = 0\n",
    "    for i in range(len(pred_str)):\n",
    "        (error, substitute, delete, insert, ref_length) \\\n",
    "                = calculate_error(pred_str[i], label_str[i])\n",
    "\n",
    "        # 総誤り数を累積する\n",
    "        total_err += error\n",
    "        total_sub += substitute\n",
    "        total_del += delete\n",
    "        total_ins += insert\n",
    "        total_length += ref_length\n",
    "        \n",
    "    err_rate = 100.0 * total_err / total_length\n",
    "    sub_rate = 100.0 * total_sub / total_length\n",
    "    del_rate = 100.0 * total_del / total_length\n",
    "    ins_rate = 100.0 * total_ins / total_length\n",
    "\n",
    "    return {\"er\": err_rate, 'sr':sub_rate, 'dr':del_rate, 'ir':ins_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c31e80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    #\"facebook/wav2vec2-base\", \n",
    "    #'facebook/wav2vec2-large-960h-lv60-self',\n",
    "    #'facebook/wav2vec2-large-xlsr-53',\n",
    "    'charsiu/zh_w2v2_tiny_fc_10ms',\n",
    "    attention_dropout=0.2,\n",
    "    hidden_dropout=0.2,\n",
    "    feat_proj_dropout=0.2,\n",
    "    mask_time_prob=0.1,\n",
    "    layerdrop=0.2,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    diversity_loss_weight=100\n",
    ")\n",
    "\n",
    "model.lm_head = nn.Linear(384, len(processor.tokenizer))\n",
    "model.config.vocab_size=len(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1731e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Config {\n",
       "  \"_name_or_path\": \"charsiu/zh_w2v2_tiny_fc_10ms\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"adapter_kernel_size\": 3,\n",
       "  \"adapter_stride\": 2,\n",
       "  \"add_adapter\": false,\n",
       "  \"apply_spec_augment\": true,\n",
       "  \"architectures\": [\n",
       "    \"Wav2Vec2ForFrameClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.2,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classifier_proj_size\": 256,\n",
       "  \"codevector_dim\": 256,\n",
       "  \"contrastive_logits_temperature\": 0.1,\n",
       "  \"conv_bias\": false,\n",
       "  \"conv_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512\n",
       "  ],\n",
       "  \"conv_kernel\": [\n",
       "    10,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"conv_stride\": [\n",
       "    5,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    1\n",
       "  ],\n",
       "  \"ctc_loss_reduction\": \"mean\",\n",
       "  \"ctc_zero_infinity\": false,\n",
       "  \"diversity_loss_weight\": 100,\n",
       "  \"do_stable_layer_norm\": false,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feat_extract_activation\": \"gelu\",\n",
       "  \"feat_extract_norm\": \"group\",\n",
       "  \"feat_proj_dropout\": 0.2,\n",
       "  \"feat_quantizer_dropout\": 0.0,\n",
       "  \"final_dropout\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.2,\n",
       "  \"hidden_size\": 384,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"layerdrop\": 0.2,\n",
       "  \"mask_feature_length\": 10,\n",
       "  \"mask_feature_min_masks\": 0,\n",
       "  \"mask_feature_prob\": 0.0,\n",
       "  \"mask_time_length\": 10,\n",
       "  \"mask_time_min_masks\": 2,\n",
       "  \"mask_time_prob\": 0.1,\n",
       "  \"model_type\": \"wav2vec2\",\n",
       "  \"num_adapter_layers\": 3,\n",
       "  \"num_attention_heads\": 6,\n",
       "  \"num_codevector_groups\": 2,\n",
       "  \"num_codevectors_per_group\": 320,\n",
       "  \"num_conv_pos_embedding_groups\": 16,\n",
       "  \"num_conv_pos_embeddings\": 128,\n",
       "  \"num_feat_extract_layers\": 7,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"num_negatives\": 20,\n",
       "  \"output_hidden_size\": 384,\n",
       "  \"pad_token_id\": 25,\n",
       "  \"proj_codevector_dim\": 256,\n",
       "  \"tdnn_dilation\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"tdnn_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    1500\n",
       "  ],\n",
       "  \"tdnn_kernel\": [\n",
       "    5,\n",
       "    3,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"use_weighted_layer_sum\": false,\n",
       "  \"vocab_size\": 26,\n",
       "  \"xvector_output_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e438a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(1,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=384, bias=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(384, 384, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=384, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=384, bias=True)\n",
       "            (output_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=384, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deaec822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23323674"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47658607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TRAIN_ALL_WEIGHTS:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801b8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1466b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 5 * len(train)//32\n",
    "num_total_steps = num_train_epochs * len(train)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "815ae6c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=20,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=True,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_min_num_params=0,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=2,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./wav2vec2_tiny_ja_roman/runs/Jul29_01-06-17_itsuki-Z490-S01,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=50,\n",
       "optim=OptimizerNames.ADAMW_HF,\n",
       "output_dir=./wav2vec2_tiny_ja_roman,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=16,\n",
       "per_device_train_batch_size=16,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=./wav2vec2_tiny_ja_roman,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.EPOCH,\n",
       "save_total_limit=5,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=742,\n",
       "weight_decay=1e-05,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=f\"./wav2vec2_tiny_ja_{tgt}\",\n",
    "  group_by_length=False,\n",
    "  per_device_train_batch_size=per_device_train_batch_size,\n",
    "  gradient_accumulation_steps=32//per_device_train_batch_size,\n",
    "  per_device_eval_batch_size=per_device_train_batch_size,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  num_train_epochs=num_train_epochs,\n",
    "  #fp16=True,\n",
    "  save_strategy='epoch',\n",
    "  fp16_full_eval=True,\n",
    "  logging_steps=10,\n",
    "  learning_rate=lr,\n",
    "  warmup_steps=warmup_steps,\n",
    "  save_total_limit=5,\n",
    "  weight_decay=1e-5,\n",
    "  dataloader_num_workers=os.cpu_count(),\n",
    "  prediction_loss_only=False,\n",
    "  lr_scheduler_type='linear',\n",
    "  #eval_steps=10,\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9695f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fe773690940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=mtr_leven,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.feature_extractor\n",
    ")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0d8c2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8873632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4750\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 7400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7400' max='7400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7400/7400 2:01:04, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Er</th>\n",
       "      <th>Sr</th>\n",
       "      <th>Dr</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.132700</td>\n",
       "      <td>4.372558</td>\n",
       "      <td>95.274490</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>94.419790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.701900</td>\n",
       "      <td>4.091608</td>\n",
       "      <td>96.507232</td>\n",
       "      <td>0.649244</td>\n",
       "      <td>95.857988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.280500</td>\n",
       "      <td>3.986387</td>\n",
       "      <td>96.466141</td>\n",
       "      <td>0.608153</td>\n",
       "      <td>95.857988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.261400</td>\n",
       "      <td>2.932758</td>\n",
       "      <td>98.841223</td>\n",
       "      <td>0.123274</td>\n",
       "      <td>98.717949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.764100</td>\n",
       "      <td>2.818458</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>2.011886</td>\n",
       "      <td>99.983563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.983563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.384135</td>\n",
       "      <td>13.001315</td>\n",
       "      <td>3.287311</td>\n",
       "      <td>8.612755</td>\n",
       "      <td>1.101249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.217987</td>\n",
       "      <td>6.319855</td>\n",
       "      <td>2.638067</td>\n",
       "      <td>2.646285</td>\n",
       "      <td>1.035503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>0.156759</td>\n",
       "      <td>4.832347</td>\n",
       "      <td>1.873767</td>\n",
       "      <td>2.358646</td>\n",
       "      <td>0.599934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.138439</td>\n",
       "      <td>3.944773</td>\n",
       "      <td>1.586128</td>\n",
       "      <td>1.545036</td>\n",
       "      <td>0.813609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.132610</td>\n",
       "      <td>4.059829</td>\n",
       "      <td>1.553254</td>\n",
       "      <td>1.191650</td>\n",
       "      <td>1.314924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.115103</td>\n",
       "      <td>3.772189</td>\n",
       "      <td>1.290270</td>\n",
       "      <td>1.520381</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>0.113319</td>\n",
       "      <td>3.320184</td>\n",
       "      <td>1.364234</td>\n",
       "      <td>1.290270</td>\n",
       "      <td>0.665680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>3.016108</td>\n",
       "      <td>1.331361</td>\n",
       "      <td>1.150559</td>\n",
       "      <td>0.534188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.101518</td>\n",
       "      <td>2.753123</td>\n",
       "      <td>1.142341</td>\n",
       "      <td>1.084813</td>\n",
       "      <td>0.525970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.101047</td>\n",
       "      <td>2.876397</td>\n",
       "      <td>1.216305</td>\n",
       "      <td>1.150559</td>\n",
       "      <td>0.509533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.094356</td>\n",
       "      <td>2.720250</td>\n",
       "      <td>1.257396</td>\n",
       "      <td>0.986193</td>\n",
       "      <td>0.476660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.094720</td>\n",
       "      <td>2.802433</td>\n",
       "      <td>1.240960</td>\n",
       "      <td>1.093031</td>\n",
       "      <td>0.468442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.093791</td>\n",
       "      <td>2.769560</td>\n",
       "      <td>1.166995</td>\n",
       "      <td>1.191650</td>\n",
       "      <td>0.410914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.090721</td>\n",
       "      <td>2.473702</td>\n",
       "      <td>1.117686</td>\n",
       "      <td>1.076594</td>\n",
       "      <td>0.279421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>2.621631</td>\n",
       "      <td>1.224523</td>\n",
       "      <td>0.936884</td>\n",
       "      <td>0.460224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.093908</td>\n",
       "      <td>2.531229</td>\n",
       "      <td>1.166995</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.402696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.093778</td>\n",
       "      <td>2.523011</td>\n",
       "      <td>1.109467</td>\n",
       "      <td>0.830046</td>\n",
       "      <td>0.583498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>2.366864</td>\n",
       "      <td>1.010848</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.550625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.087759</td>\n",
       "      <td>2.383300</td>\n",
       "      <td>0.977975</td>\n",
       "      <td>0.928665</td>\n",
       "      <td>0.476660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>0.088203</td>\n",
       "      <td>2.276463</td>\n",
       "      <td>0.977975</td>\n",
       "      <td>0.871137</td>\n",
       "      <td>0.427350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.087435</td>\n",
       "      <td>2.153189</td>\n",
       "      <td>0.920447</td>\n",
       "      <td>0.772518</td>\n",
       "      <td>0.460224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.085116</td>\n",
       "      <td>2.227153</td>\n",
       "      <td>0.953320</td>\n",
       "      <td>0.756082</td>\n",
       "      <td>0.517751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.086625</td>\n",
       "      <td>2.227153</td>\n",
       "      <td>0.904011</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.443787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>2.284681</td>\n",
       "      <td>0.953320</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.567061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.085722</td>\n",
       "      <td>2.284681</td>\n",
       "      <td>0.920447</td>\n",
       "      <td>0.862919</td>\n",
       "      <td>0.501315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>2.071006</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.821828</td>\n",
       "      <td>0.394477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.081929</td>\n",
       "      <td>2.062788</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.369822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.082723</td>\n",
       "      <td>2.169625</td>\n",
       "      <td>0.895792</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.509533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>0.085950</td>\n",
       "      <td>2.079224</td>\n",
       "      <td>0.953320</td>\n",
       "      <td>0.698554</td>\n",
       "      <td>0.427350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.084603</td>\n",
       "      <td>2.029915</td>\n",
       "      <td>0.912229</td>\n",
       "      <td>0.706772</td>\n",
       "      <td>0.410914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.086011</td>\n",
       "      <td>2.186062</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.731427</td>\n",
       "      <td>0.493097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>2.062788</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.690335</td>\n",
       "      <td>0.484878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.086684</td>\n",
       "      <td>2.021696</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.632807</td>\n",
       "      <td>0.501315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>1.997041</td>\n",
       "      <td>0.838264</td>\n",
       "      <td>0.731427</td>\n",
       "      <td>0.427350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.086766</td>\n",
       "      <td>2.038133</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.706772</td>\n",
       "      <td>0.452005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.085079</td>\n",
       "      <td>2.038133</td>\n",
       "      <td>0.895792</td>\n",
       "      <td>0.649244</td>\n",
       "      <td>0.493097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.085079</td>\n",
       "      <td>1.997041</td>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>0.452005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.085153</td>\n",
       "      <td>2.054569</td>\n",
       "      <td>0.871137</td>\n",
       "      <td>0.706772</td>\n",
       "      <td>0.476660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.082676</td>\n",
       "      <td>2.054569</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.706772</td>\n",
       "      <td>0.493097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.084285</td>\n",
       "      <td>2.062788</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.673899</td>\n",
       "      <td>0.509533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.085368</td>\n",
       "      <td>1.947732</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.624589</td>\n",
       "      <td>0.468442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.085161</td>\n",
       "      <td>1.980605</td>\n",
       "      <td>0.838264</td>\n",
       "      <td>0.690335</td>\n",
       "      <td>0.452005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.084056</td>\n",
       "      <td>1.972387</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.682117</td>\n",
       "      <td>0.435569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.084152</td>\n",
       "      <td>1.988823</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.673899</td>\n",
       "      <td>0.435569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "nnn \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "nn \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "nn \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "nn \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-148\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-148/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-148/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-148/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "nnn \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "n \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "n \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "n \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-296\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-296/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-296/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-296/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "nn \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "n \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "n \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "nn \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-444\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-444/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-444/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-444/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      " \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      " \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      " \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      " \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-592\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-592/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-592/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-592/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      " \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      " \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      " \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      " \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-740\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-740/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-740/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-740/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      " \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      " \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      " \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      " \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-888\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-888/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-888/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-888/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-148] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizomareshiakarakawanakutwanaranainoresk \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyobikesenkaidawanannoshintemonaimamashuroshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "joonginnwawatashigadetaoyugametatokokatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishukanshitessononiyoswaontoninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsatsuwakenkoonotaromeetatohitejuyodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1036\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1036/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1036/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1036/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-296] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizaomareeshiakarakawanakuteowanaranainoresu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobikeesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetaougametatokokuatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyosuwahhontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsatsuwakenkoonotaraomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1184\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1184/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1184/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1184/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-444] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizoomareeshiakarakawanakutewanaranainoresu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemnaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetaoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyusowahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "kyetsaatsuwakenkoonotaromeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1332\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1332/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1332/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1332/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-592] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizoomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshinashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "kyeutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1480\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1480/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1480/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1480/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-740] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "kyeutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1628\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1628/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1628/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1628/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-888] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "keutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1776\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1776/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1776/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1776/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1036] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-1924\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-1924/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-1924/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-1924/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1184] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuriooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2072\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2072/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2072/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2072/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1332] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "keutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2220\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2220/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2220/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2220/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwananmoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "keutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2368\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2368/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2368/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2368/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1628] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2516\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2516/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2516/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2516/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1776] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "kyutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2664\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2664/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2664/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2664/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-1924] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2812\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2812/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2812/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2812/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2072] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-2960\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-2960/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-2960/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-2960/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2220] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3108\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3108/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3108/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3108/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2368] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3256\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3256/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3256/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3256/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2516] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3404\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3404/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3404/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3404/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2664] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3552\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3552/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3552/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3552/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2812] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3700\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3700/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3700/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3700/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-2960] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3848\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3848/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3848/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3848/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3108] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-3996\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-3996/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-3996/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-3996/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizowomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-4144\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-4144/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-4144/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-4144/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3404] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-4292\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-4292/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-4292/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-4292/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3552] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-4440\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-4440/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-4440/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-4440/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "kutsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-4588\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-4588/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-4588/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-4588/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3848] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-4736\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-4736/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-4736/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-4736/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-3996] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-4884\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-4884/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-4884/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-4884/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-4144] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5032\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5032/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5032/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5032/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-4292] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5180\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5180/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5180/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5180/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-4440] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5328\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5328/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5328/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5328/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-4588] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5476\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5476/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5476/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5476/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-4736] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5624\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5624/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5624/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5624/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-4884] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5772\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5772/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5772/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5772/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5032] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-5920\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-5920/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-5920/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-5920/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5180] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6068\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6068/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6068/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6068/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5328] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6216\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6216/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6216/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6216/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5476] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6364\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6364/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6364/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6364/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5624] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6512\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6512/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6512/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6512/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5772] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6660\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6660/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6660/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6660/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-5920] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6808\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6808/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6808/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6808/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-6068] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-6956\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-6956/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-6956/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-6956/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-6216] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-7104\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-7104/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-7104/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-7104/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-6364] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-7252\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-7252/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-7252/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-7252/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-6512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizuwomareeshiakarakawanakutewanaranainodesu \n",
      " mizuwomareeshiakarakawanakutewanaranainodesu\n",
      "mokuyoobiteesenkaidanwanannoshintemonaimamashuuryooshimashita \n",
      " mokuyoobiteesenkaidanwanannoshintenmonaimamashuuryooshimashita\n",
      "jooinginnwawatashigadeetawoyugametatokokuhatsushita \n",
      " jooingiinwawatashigadeetawoyugametatokokuhatsushita\n",
      "ishuukanshitesononyuusuwahontooninatta \n",
      " isshuukanshitesononyuusuwahontooninatta\n",
      "ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu \n",
      " ketsuatsuwakenkoonoparomeetaatoshitejuuyoodearu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./wav2vec2_tiny_ja_roman/checkpoint-7400\n",
      "Configuration saved in ./wav2vec2_tiny_ja_roman/checkpoint-7400/config.json\n",
      "Model weights saved in ./wav2vec2_tiny_ja_roman/checkpoint-7400/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2_tiny_ja_roman/checkpoint-7400/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2_tiny_ja_roman/checkpoint-6660] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 49min 1s, sys: 3min 17s, total: 1h 52min 18s\n",
      "Wall time: 2h 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7400, training_loss=0.7016970042038608, metrics={'train_runtime': 7267.7397, 'train_samples_per_second': 32.679, 'train_steps_per_second': 1.018, 'total_flos': 5.463213955722643e+18, 'train_loss': 0.7016970042038608, 'epoch': 50.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824c3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
